{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# File specific imports\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "rnd.seed(42)\n",
    "\n",
    "# Show all columns when displaying dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (7,9,17,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/DIAGNOSES_ICD.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'HADM_ID', 'SEQ_NUM', 'ICD9_CODE']\n",
    "diagnoses = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/D_ICD_DIAGNOSES.csv'\n",
    "cols_to_keep = ['ICD9_CODE', 'SHORT_TITLE']\n",
    "dir_diagnoses = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/ADMISSIONS.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'ADMISSION_LOCATION', 'ETHNICITY', 'DIAGNOSIS']\n",
    "admissions = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/PATIENTS.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'GENDER', 'DOB', 'EXPIRE_FLAG']\n",
    "patients = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/INPUTEVENTS_CV.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'ORDERID', 'CHARTTIME', 'ITEMID', 'AMOUNT', 'AMOUNTUOM', 'ORIGINALAMOUNT', 'ORIGINALAMOUNTUOM', 'ORIGINALRATE', 'ORIGINALRATEUOM', 'RATE', 'RATEUOM'] # 'RATE', 'RATEUOM', 'STOPPED' are full of NaN\n",
    "inputevents_cv = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/INPUTEVENTS_MV.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'ORDERID', 'STARTTIME', 'ENDTIME', 'ITEMID', 'AMOUNT', 'AMOUNTUOM', 'RATE', 'RATEUOM', 'ORDERCATEGORYNAME', 'ORDERCATEGORYDESCRIPTION']\n",
    "inputevents_mv = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/LABEVENTS.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'HADM_ID', 'ITEMID', 'CHARTTIME', 'VALUE', 'VALUENUM', 'VALUEUOM', 'FLAG'] # 'HADM_ID' is full of NaN\n",
    "labevents = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/D_ITEMS.csv'\n",
    "cols_to_keep = ['ITEMID', 'LABEL'] #'CATEGORY', 'UNITNAME', 'PARAM_TYPE' are full of NaN\n",
    "d_items = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/D_LABITEMS.csv'\n",
    "cols_to_keep = ['ITEMID', 'LABEL', 'FLUID', 'CATEGORY']\n",
    "d_labitems = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "admissions = admissions.applymap(str)\n",
    "patients = patients.applymap(str)\n",
    "inputevents_cv = inputevents_cv.applymap(str)\n",
    "inputevents_mv  = inputevents_mv.applymap(str)\n",
    "labevents  = labevents.applymap(str) \n",
    "d_items = d_items.applymap(str)\n",
    "d_labitems = d_labitems.applymap(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATIENT INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine admissions and patients\n",
    "patient_info = pd.merge(admissions, patients, on = ['SUBJECT_ID'])\n",
    "\n",
    "# Change Ethnicity to White/Non-White\n",
    "ethnicity = patient_info['ETHNICITY']\n",
    "\n",
    "def get_ethnicity(value):\n",
    "    if value == 'WHITE':\n",
    "        return 'WHITE'\n",
    "    else:\n",
    "        return 'NOT WHITE'\n",
    "\n",
    "list_ethnicity = [get_ethnicity(value) for value in ethnicity]\n",
    "\n",
    "patient_info = patient_info.drop('ETHNICITY', axis = 1)\n",
    "df_ethnicity = pd.DataFrame({'ETHNICITY' : list_ethnicity})\n",
    "patient_info = pd.concat([patient_info, df_ethnicity], axis=1)\n",
    "\n",
    "# Add ages\n",
    "DoB = patient_info['DOB']\n",
    "admDate = patient_info['ADMITTIME']\n",
    "\n",
    "def get_age (birth, current):\n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    birth = birth.replace('-', ' ')\n",
    "    birth = birth.replace(':', ' ')\n",
    "    current = current.replace('-', ' ')\n",
    "    current = current.replace(':', ' ')\n",
    "\n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    birth = birth.split(' ')\n",
    "    current = current.split(' ')\n",
    "\n",
    "    #convert to integers\n",
    "    birth = [int(i) for i in birth]\n",
    "    current = [int(i) for i in current]\n",
    "    \n",
    "    #get age and return it\n",
    "    birth = datetime.datetime(birth[0], birth[1], birth[2], birth[3], birth[4], birth[5])\n",
    "    current = datetime.datetime(current[0], current[1], current[2], current[3], current[4], current[5])\n",
    "    age = relativedelta(current, birth).years\n",
    "    \n",
    "    #adjust for 89+ category\n",
    "    if age == 300:\n",
    "        age = 89\n",
    "    \n",
    "    return age\n",
    "\n",
    "def get_age_category(age):\n",
    "    if age > 88:\n",
    "        return ('89+')\n",
    "    elif age > 60:\n",
    "        return('Elderly')\n",
    "    elif age > 50:\n",
    "        return('50s')\n",
    "    elif age > 40:\n",
    "        return('40s')\n",
    "    elif age > 30:\n",
    "        return('30s')\n",
    "    elif age > 17:\n",
    "        return('20s')\n",
    "    else:\n",
    "        return('Child')\n",
    "\n",
    "ages = []\n",
    "age_categories = []\n",
    "\n",
    "for i in range(len(DoB)):\n",
    "    ages.append(get_age(DoB[i], admDate[i]))\n",
    "\n",
    "for age in ages:\n",
    "    age_categories.append(get_age_category(age))\n",
    "\n",
    "ages_df = pd.DataFrame({'AGE' : ages})\n",
    "ages_cat_df = pd.DataFrame({'AGE_CAT' : age_categories})\n",
    "patient_info = pd.concat([patient_info, ages_df], axis=1)\n",
    "patient_info = pd.concat([patient_info, ages_cat_df], axis=1)\n",
    "\n",
    "# Add LOS\n",
    "admDate = patient_info['ADMITTIME']\n",
    "dischDate = patient_info['DISCHTIME']\n",
    "\n",
    "def get_los (admit, disch):\n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    admit = admit.replace('-', ' ')\n",
    "    admit = admit.replace(':', ' ')\n",
    "    disch = disch.replace('-', ' ')\n",
    "    disch = disch.replace(':', ' ')\n",
    "\n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    admit = admit.split(' ')\n",
    "    disch = disch.split(' ')\n",
    "\n",
    "    #convert to integers\n",
    "    admit = [int(i) for i in admit]\n",
    "    disch = [int(i) for i in disch]\n",
    "    \n",
    "    #get los and return it\n",
    "    admit = datetime.datetime(admit[0], admit[1], admit[2], admit[3], admit[4], admit[5])\n",
    "    disch = datetime.datetime(disch[0], disch[1], disch[2], disch[3], disch[4], disch[5])\n",
    "    los = (disch-admit).total_seconds()/3600\n",
    "    los = round((los/24), 1)\n",
    "\n",
    "    return los\n",
    "\n",
    "los = []\n",
    "\n",
    "for i in range(len(admDate)):\n",
    "    los.append(get_los(admDate[i], dischDate[i]))\n",
    "    \n",
    "los_df = pd.DataFrame({'LOS' : los})\n",
    "patient_info = pd.concat([patient_info, los_df], axis = 1)\n",
    "\n",
    "# Get Day/Night (day is between 8 am : 8 pm)\n",
    "admTime = patient_info['ADMITTIME']\n",
    "\n",
    "def get_day_night (value):\n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    value = value.replace('-', ' ')\n",
    "    value = value.replace(':', ' ')\n",
    "    \n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    date = value.split(' ')\n",
    "    \n",
    "    #leave hour/min/sec, convert to integers\n",
    "    hour = date[3]\n",
    "    int_hour = int(hour)\n",
    "    \n",
    "    #get day/night and return it\n",
    "    if 7 < int_hour < 21:\n",
    "        return 'DAY'\n",
    "    else:\n",
    "        return 'NIGHT'\n",
    "\n",
    "day_night = [get_day_night(value) for value in admTime]\n",
    "\n",
    "day_night_df = pd.DataFrame({'DAY_NIGHT' : day_night})\n",
    "patient_info = pd.concat([patient_info, day_night_df], axis=1)\n",
    "\n",
    "# Get admission day\n",
    "admTime = patient_info['ADMITTIME']\n",
    "\n",
    "def get_day_of_week (value):\n",
    "    date = []\n",
    "    int_date = []\n",
    "    day_of_week = []\n",
    "    \n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    value = value.replace('-', ' ')\n",
    "    value = value.replace(':', ' ')\n",
    "    \n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    date = value.split(' ')\n",
    "    \n",
    "    #delete hour/min/sec, convert to integers\n",
    "    del date[3:6]\n",
    "    int_date = [int(i) for i in date]\n",
    "    \n",
    "    #get day of week and return it\n",
    "    day_of_week = datetime.date(int_date[0], int_date[1], int_date[2]).weekday()\n",
    "    \n",
    "    return day_of_week\n",
    "\n",
    "\n",
    "admTime_weekday = [get_day_of_week(value) for value in admTime]\n",
    "\n",
    "weekday_data_df = pd.DataFrame({'ADM_DAY' : admTime_weekday})\n",
    "patient_info = pd.concat([patient_info, weekday_data_df], axis=1)\n",
    "\n",
    "# Clean up columns\n",
    "patient_times_info = patient_info[['SUBJECT_ID', 'ADMITTIME', 'DISCHTIME', 'DOB']].copy()\n",
    "patient_times_info = patient_times_info.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "\n",
    "patient_info = patient_info.drop(['ADMITTIME', 'DISCHTIME', 'DOB'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUTEVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge d_items onto inputevents_cv, and inputevents_mv separately\n",
    "inputevents_cv = pd.merge(inputevents_cv, d_items, on = 'ITEMID')\n",
    "inputevents_mv = pd.merge(inputevents_mv, d_items, on = 'ITEMID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LABEVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert labevents[FLAG] : NaN to 0, abnomal to 1\n",
    "labevents['FLAG'] = labevents['FLAG'].replace('nan', 0)\n",
    "labevents['FLAG'] = labevents['FLAG'].replace('abnormal', 1)\n",
    "\n",
    "# Merge d_labitems onto labevents \n",
    "labevents = pd.merge(labevents, d_labitems, on = 'ITEMID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heparin Data Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMISSION_LOCATION</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>EXPIRE_FLAG</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGE_CAT</th>\n",
       "      <th>LOS</th>\n",
       "      <th>DAY_NIGHT</th>\n",
       "      <th>ADM_DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>165315</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>BENZODIAZEPINE OVERDOSE</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>64</td>\n",
       "      <td>Elderly</td>\n",
       "      <td>1.1</td>\n",
       "      <td>DAY</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>152223</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>CORONARY ARTERY DISEASE\\CORONARY ARTERY BYPASS...</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>71</td>\n",
       "      <td>Elderly</td>\n",
       "      <td>5.5</td>\n",
       "      <td>NIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>124321</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>BRAIN MASS</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>75</td>\n",
       "      <td>Elderly</td>\n",
       "      <td>6.8</td>\n",
       "      <td>DAY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>161859</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>INTERIOR MYOCARDIAL INFARCTION</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>39</td>\n",
       "      <td>30s</td>\n",
       "      <td>2.9</td>\n",
       "      <td>DAY</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>129635</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>ACUTE CORONARY SYNDROME</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>58</td>\n",
       "      <td>50s</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NIGHT</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SUBJECT_ID HADM_ID         ADMISSION_LOCATION  \\\n",
       "0         22  165315       EMERGENCY ROOM ADMIT   \n",
       "1         23  152223  PHYS REFERRAL/NORMAL DELI   \n",
       "2         23  124321  TRANSFER FROM HOSP/EXTRAM   \n",
       "3         24  161859  TRANSFER FROM HOSP/EXTRAM   \n",
       "4         25  129635       EMERGENCY ROOM ADMIT   \n",
       "\n",
       "                                           DIAGNOSIS GENDER EXPIRE_FLAG  \\\n",
       "0                            BENZODIAZEPINE OVERDOSE      F           0   \n",
       "1  CORONARY ARTERY DISEASE\\CORONARY ARTERY BYPASS...      M           0   \n",
       "2                                         BRAIN MASS      M           0   \n",
       "3                     INTERIOR MYOCARDIAL INFARCTION      M           0   \n",
       "4                            ACUTE CORONARY SYNDROME      M           0   \n",
       "\n",
       "  ETHNICITY  AGE  AGE_CAT  LOS DAY_NIGHT  ADM_DAY  \n",
       "0     WHITE   64  Elderly  1.1       DAY        5  \n",
       "1     WHITE   71  Elderly  5.5     NIGHT        0  \n",
       "2     WHITE   75  Elderly  6.8       DAY        1  \n",
       "3     WHITE   39      30s  2.9       DAY        5  \n",
       "4     WHITE   58      50s  3.5     NIGHT        6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. UNIQUE ADULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Get only first ICU stay for each patient\n",
    "patient_info = patient_info.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "\n",
    "# Find all TPA patients\n",
    "word_list = ['TPA', 'tpa']\n",
    "tpa_cv = inputevents_cv.loc[inputevents_cv['LABEL'].isin(word_list)]\n",
    "tpa_mv = inputevents_mv[inputevents_mv['LABEL'].str.contains('|'.join(word_list))]\n",
    "\n",
    "# Clean up\n",
    "tpa_mv['RATE'] = pd.to_numeric(tpa_mv['RATE']).round(decimals=1).astype(str)\n",
    "tpa_cv = tpa_cv[tpa_cv.ORIGINALRATE != 'nan']\n",
    "tpa_cv = tpa_cv[tpa_cv.AMOUNT != 'nan']\n",
    "tpa_cv['ORIGINALRATE'] = pd.to_numeric(tpa_cv['ORIGINALRATE']).round(decimals=1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PT recieving TPA:  48\n"
     ]
    }
   ],
   "source": [
    "# Count total patients recieving TPA\n",
    "gp_cv = tpa_cv['SUBJECT_ID'].unique().tolist()\n",
    "gp_mv = tpa_mv['SUBJECT_ID'].unique().tolist()\n",
    "patient_count = len(gp_cv) + len(gp_mv)\n",
    "print('Total PT recieving TPA: ', patient_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 12)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update patient_info to heparin_patients\n",
    "patient_list = gp_cv + gp_mv\n",
    "\n",
    "tpa_patients = pd.DataFrame({'SUBJECT_ID' : patient_list})\n",
    "tpa_patients = tpa_patients.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "tpa_patients = pd.merge(tpa_patients, patient_info, on = 'SUBJECT_ID')\n",
    "tpa_patients.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. aPTT MEASUREMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PT with aPTT tests:  32\n"
     ]
    }
   ],
   "source": [
    "# Find all aPTT measurements\n",
    "word_list = ['PTT']\n",
    "aPTT = labevents[labevents['LABEL'].str.contains('|'.join(word_list))]\n",
    "aPTT = aPTT.reset_index(drop = True)\n",
    "aPTT['HADM_ID'] = aPTT['HADM_ID'].str.replace('.0', '')\n",
    "\n",
    "# Remove repeat HADM_ID\n",
    "word_list = tpa_patients['HADM_ID'].tolist()\n",
    "aPTT = aPTT.loc[aPTT['HADM_ID'].isin(word_list)]\n",
    "\n",
    "# Create Groups\n",
    "gp_ptt = aPTT['SUBJECT_ID'].unique().tolist()\n",
    "patient_count = len(gp_ptt)\n",
    "\n",
    "print('Total PT with aPTT tests: ', patient_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 12)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update tpa_patients\n",
    "patient_list_ptt = gp_ptt\n",
    "aPTT_patients = pd.DataFrame({'SUBJECT_ID' : patient_list_ptt})\n",
    "tpa_patients = pd.merge(tpa_patients, aPTT_patients, on = 'SUBJECT_ID')\n",
    "tpa_patients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptts = aPTT['VALUE']\n",
    "\n",
    "def get_aPTT(ptt):\n",
    "    if ptt == '>150':\n",
    "        return ('150.0')\n",
    "    elif ptt == '>150.0':\n",
    "        return ('150.0')\n",
    "    elif ptt == '> 150':\n",
    "        return ('150.0')\n",
    "    elif len(ptt) > 5:\n",
    "        return (None)\n",
    "    elif ptt == 'ERROR':\n",
    "        return (None)\n",
    "    ptt = ptt.replace('..', '.')\n",
    "    return(ptt)\n",
    "\n",
    "def get_aPTT_category(ptt):\n",
    "    if ptt == None:\n",
    "        return (None)\n",
    "    ptt = float(ptt)\n",
    "    if ptt > 100:\n",
    "        return ('SUPRA-TH')\n",
    "    elif ptt < 60:\n",
    "        return('SUB-TH')\n",
    "    else:\n",
    "        return('TH')\n",
    "\n",
    "ptts_new = []\n",
    "ptt_categories = []\n",
    "\n",
    "for ptt in ptts:\n",
    "    ptts_new.append(get_aPTT(ptt))\n",
    "\n",
    "for ptt in ptts_new:\n",
    "    ptt_categories.append(get_aPTT_category(ptt))\n",
    "\n",
    "ptt_df = pd.DataFrame({'aPTT' : ptts_new})\n",
    "ptt_cat_df = pd.DataFrame({'aPTT_CAT' : ptt_categories})\n",
    "\n",
    "aPTT = aPTT.reset_index(drop = True)\n",
    "aPTT = pd.concat([aPTT, ptt_df], axis = 1)\n",
    "aPTT = pd.concat([aPTT, ptt_cat_df], axis = 1)\n",
    "aPTT = aPTT[['SUBJECT_ID', 'HADM_ID', 'ITEMID', 'CHARTTIME', 'aPTT', 'VALUEUOM', 'LABEL', 'aPTT_CAT', 'FLUID', 'CATEGORY']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3\\. NON TRANSFERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 12)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpa_patients = tpa_patients[tpa_patients.ADMISSION_LOCATION != 'TRANSFER FROM SKILLED NUR']\n",
    "tpa_patients = tpa_patients[tpa_patients.ADMISSION_LOCATION != 'TRANSFER FROM HOSP/EXTRAM']\n",
    "tpa_patients = tpa_patients[tpa_patients.ADMISSION_LOCATION != 'TRANSFER FROM OTHER HEALT']\n",
    "tpa_patients = tpa_patients[tpa_patients.ADMISSION_LOCATION != '** INFO NOT AVAILABLE **']\n",
    "\n",
    "tpa_patients.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dosage Start Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_length (first, second):\n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    first = first.replace('-', ' ')\n",
    "    first = first.replace(':', ' ')\n",
    "    second = second.replace('-', ' ')\n",
    "    second = second.replace(':', ' ')\n",
    "\n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    first = first.split(' ')\n",
    "    second = second.split(' ')\n",
    "\n",
    "    #convert to integers\n",
    "    first = [int(i) for i in first]\n",
    "    second = [int(i) for i in second]\n",
    "    \n",
    "    #get los and return it\n",
    "    first = datetime.datetime(first[0], first[1], first[2], first[3], first[4], first[5])\n",
    "    second = datetime.datetime(second[0], second[1], second[2], second[3], second[4], second[5])\n",
    "    length = (second-first).total_seconds()/3600\n",
    "    length = round(length, 1)\n",
    "\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ICUSTAY_ID</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>AMOUNT</th>\n",
       "      <th>AMOUNTUOM</th>\n",
       "      <th>RATE</th>\n",
       "      <th>RATEUOM</th>\n",
       "      <th>ORDERID</th>\n",
       "      <th>ORIGINALAMOUNT</th>\n",
       "      <th>ORIGINALAMOUNTUOM</th>\n",
       "      <th>ORIGINALRATE</th>\n",
       "      <th>ORIGINALRATEUOM</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>TOTALAMOUNT</th>\n",
       "      <th>ZERODATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17202979</th>\n",
       "      <td>11684</td>\n",
       "      <td>172672</td>\n",
       "      <td>279134.0</td>\n",
       "      <td>2106-10-13 17:00:00</td>\n",
       "      <td>30135</td>\n",
       "      <td>50.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1422147</td>\n",
       "      <td>100.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ml/hr</td>\n",
       "      <td>TPA</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1111-11-11 11:11:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17202980</th>\n",
       "      <td>11684</td>\n",
       "      <td>172672</td>\n",
       "      <td>279134.0</td>\n",
       "      <td>2106-10-13 23:00:00</td>\n",
       "      <td>30135</td>\n",
       "      <td>50.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>6919093</td>\n",
       "      <td>100.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ml/hr</td>\n",
       "      <td>TPA</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1111-11-11 11:11:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17202981</th>\n",
       "      <td>11684</td>\n",
       "      <td>172672</td>\n",
       "      <td>279134.0</td>\n",
       "      <td>2106-10-14 01:00:00</td>\n",
       "      <td>30135</td>\n",
       "      <td>100.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>8799</td>\n",
       "      <td>100.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ml/hr</td>\n",
       "      <td>TPA</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1111-11-11 11:11:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17202983</th>\n",
       "      <td>11684</td>\n",
       "      <td>172672</td>\n",
       "      <td>279134.0</td>\n",
       "      <td>2106-10-14 05:00:00</td>\n",
       "      <td>30135</td>\n",
       "      <td>50.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>7009975</td>\n",
       "      <td>100.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ml/hr</td>\n",
       "      <td>TPA</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1111-11-11 11:11:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17202984</th>\n",
       "      <td>11684</td>\n",
       "      <td>172672</td>\n",
       "      <td>279134.0</td>\n",
       "      <td>2106-10-14 06:00:00</td>\n",
       "      <td>30135</td>\n",
       "      <td>50.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>4979678</td>\n",
       "      <td>100.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ml/hr</td>\n",
       "      <td>TPA</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1111-11-11 11:11:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17202985</th>\n",
       "      <td>11684</td>\n",
       "      <td>172672</td>\n",
       "      <td>279134.0</td>\n",
       "      <td>2106-10-12 22:00:00</td>\n",
       "      <td>30135</td>\n",
       "      <td>25.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>10082936</td>\n",
       "      <td>100.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ml/hr</td>\n",
       "      <td>TPA</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1111-11-11 11:11:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17202986</th>\n",
       "      <td>11684</td>\n",
       "      <td>172672</td>\n",
       "      <td>279134.0</td>\n",
       "      <td>2106-10-13 22:00:00</td>\n",
       "      <td>30135</td>\n",
       "      <td>50.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>6786745</td>\n",
       "      <td>100.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ml/hr</td>\n",
       "      <td>TPA</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1111-11-11 11:11:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17202988</th>\n",
       "      <td>11684</td>\n",
       "      <td>172672</td>\n",
       "      <td>279134.0</td>\n",
       "      <td>2106-10-12 18:00:00</td>\n",
       "      <td>30135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>10227213</td>\n",
       "      <td>100.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ml/hr</td>\n",
       "      <td>TPA</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1111-11-11 11:11:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17203025</th>\n",
       "      <td>11684</td>\n",
       "      <td>172672</td>\n",
       "      <td>279134.0</td>\n",
       "      <td>2106-10-14 08:00:00</td>\n",
       "      <td>30135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2316850</td>\n",
       "      <td>100.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ml/hr</td>\n",
       "      <td>TPA</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1111-11-11 11:11:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17203026</th>\n",
       "      <td>11684</td>\n",
       "      <td>172672</td>\n",
       "      <td>279134.0</td>\n",
       "      <td>2106-10-13 18:00:00</td>\n",
       "      <td>30135</td>\n",
       "      <td>50.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>8353411</td>\n",
       "      <td>100.0</td>\n",
       "      <td>mg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ml/hr</td>\n",
       "      <td>TPA</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1111-11-11 11:11:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SUBJECT_ID HADM_ID ICUSTAY_ID            CHARTTIME ITEMID  AMOUNT  \\\n",
       "17202979      11684  172672   279134.0  2106-10-13 17:00:00  30135    50.0   \n",
       "17202980      11684  172672   279134.0  2106-10-13 23:00:00  30135    50.0   \n",
       "17202981      11684  172672   279134.0  2106-10-14 01:00:00  30135   100.0   \n",
       "17202983      11684  172672   279134.0  2106-10-14 05:00:00  30135    50.0   \n",
       "17202984      11684  172672   279134.0  2106-10-14 06:00:00  30135    50.0   \n",
       "17202985      11684  172672   279134.0  2106-10-12 22:00:00  30135    25.0   \n",
       "17202986      11684  172672   279134.0  2106-10-13 22:00:00  30135    50.0   \n",
       "17202988      11684  172672   279134.0  2106-10-12 18:00:00  30135     0.0   \n",
       "17203025      11684  172672   279134.0  2106-10-14 08:00:00  30135     0.0   \n",
       "17203026      11684  172672   279134.0  2106-10-13 18:00:00  30135    50.0   \n",
       "\n",
       "         AMOUNTUOM RATE RATEUOM   ORDERID ORIGINALAMOUNT ORIGINALAMOUNTUOM  \\\n",
       "17202979        mg  nan     nan   1422147          100.0                mg   \n",
       "17202980        mg  nan     nan   6919093          100.0                mg   \n",
       "17202981        mg  nan     nan      8799          100.0                mg   \n",
       "17202983        mg  nan     nan   7009975          100.0                mg   \n",
       "17202984        mg  nan     nan   4979678          100.0                mg   \n",
       "17202985        mg  nan     nan  10082936          100.0                mg   \n",
       "17202986        mg  nan     nan   6786745          100.0                mg   \n",
       "17202988        mg  nan     nan  10227213          100.0                mg   \n",
       "17203025        mg  nan     nan   2316850          100.0                mg   \n",
       "17203026        mg  nan     nan   8353411          100.0                mg   \n",
       "\n",
       "         ORIGINALRATE ORIGINALRATEUOM LABEL  TOTALAMOUNT             ZERODATE  \n",
       "17202979         50.0           ml/hr   TPA        850.0  1111-11-11 11:11:11  \n",
       "17202980         50.0           ml/hr   TPA        850.0  1111-11-11 11:11:11  \n",
       "17202981         50.0           ml/hr   TPA        850.0  1111-11-11 11:11:11  \n",
       "17202983         50.0           ml/hr   TPA        850.0  1111-11-11 11:11:11  \n",
       "17202984         50.0           ml/hr   TPA        850.0  1111-11-11 11:11:11  \n",
       "17202985         50.0           ml/hr   TPA        850.0  1111-11-11 11:11:11  \n",
       "17202986         50.0           ml/hr   TPA        850.0  1111-11-11 11:11:11  \n",
       "17202988         50.0           ml/hr   TPA        850.0  1111-11-11 11:11:11  \n",
       "17203025         50.0           ml/hr   TPA        850.0  1111-11-11 11:11:11  \n",
       "17203026         50.0           ml/hr   TPA        850.0  1111-11-11 11:11:11  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpa_cv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tpa_cv['ZERODATE'] = '1111-11-11 11:11:11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "startDate = tpa_cv['ZERODATE'].tolist()\n",
    "endDate = tpa_cv['CHARTTIME'].tolist()\n",
    "\n",
    "delta_list = []\n",
    "\n",
    "for i in range(len(startDate)):\n",
    "    delta_list.append(get_length(startDate[i], endDate[i]))\n",
    "    \n",
    "delta_df = pd.DataFrame({'order_TIME' : delta_list})\n",
    "tpa_cv = tpa_mv.reset_index(drop = True)\n",
    "tpa_cv = pd.concat([tpa_mv, delta_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update heparin dosage dataframes\n",
    "word_list = tpa_patients['HADM_ID'].tolist()\n",
    "tpa_cv['HADM_ID'] = tpa_cv['HADM_ID'].str.replace('.0', '')\n",
    "tpa_cv = tpa_cv.loc[tpa_cv['HADM_ID'].isin(word_list)]\n",
    "tpa_mv = tpa_mv.loc[tpa_mv['HADM_ID'].isin(word_list)]\n",
    "\n",
    "# Sum of tPA recieved\n",
    "tpa_cv['AMOUNT'] = pd.to_numeric(tpa_cv['AMOUNT']).round(decimals=1)\n",
    "tpa_cv['TOTALAMOUNT'] = tpa_cv.groupby('SUBJECT_ID')['AMOUNT'].transform(sum)\n",
    "tpa_mv['AMOUNT'] = pd.to_numeric(tpa_mv['AMOUNT']).round(decimals=1)\n",
    "tpa_mv['TOTALAMOUNT'] = tpa_mv.groupby('SUBJECT_ID')['AMOUNT'].transform(sum)\n",
    "\n",
    "# Total hours of tPA\n",
    "# mv\n",
    "startDate = tpa_mv['STARTTIME'].tolist()\n",
    "endDate = tpa_mv['ENDTIME'].tolist()\n",
    "\n",
    "delta_list = []\n",
    "\n",
    "for i in range(len(startDate)):\n",
    "    delta_list.append(get_length(startDate[i], endDate[i]))\n",
    "    \n",
    "delta_df = pd.DataFrame({'tPA_TIME' : delta_list})\n",
    "tpa_mv = tpa_mv.reset_index(drop = True)\n",
    "tpa_mv = pd.concat([tpa_mv, delta_df], axis = 1)\n",
    "tpa_mv['tPA_LENGTH'] = tpa_mv.groupby('SUBJECT_ID')['tPA_TIME'].transform(sum)\n",
    "tpa_mv = tpa_mv.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "tpa_mv['tPA_RATE'] = tpa_mv['TOTALAMOUNT']/tpa_mv['tPA_LENGTH']\n",
    "tpa_mv = tpa_mv[['SUBJECT_ID', 'HADM_ID', 'tPA_RATE', 'RATEUOM']]\n",
    "\n",
    "# cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2440, 12)\n",
      "Total patients with first dose:  2440\n"
     ]
    }
   ],
   "source": [
    "# Extract IDs and Start Times\n",
    "dose_cv = heparin_cv[['SUBJECT_ID', 'CHARTTIME']].copy()\n",
    "dose_cv = dose_cv.rename(columns = {'CHARTTIME': 'DOSE_TIME'})\n",
    "\n",
    "dose_mv = heparin_mv[['SUBJECT_ID', 'STARTTIME']].copy()\n",
    "dose_mv = dose_mv.rename(columns = {'STARTTIME': 'DOSE_TIME'})\n",
    "\n",
    "# Combine and take First Dose\n",
    "dose_info = pd.concat([dose_cv, dose_mv])\n",
    "first_dose = dose_info.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "\n",
    "#Update patient numbers\n",
    "x = heparin_cv['SUBJECT_ID'].unique().tolist()\n",
    "y = heparin_mv['SUBJECT_ID'].unique().tolist()\n",
    "z = x+y\n",
    "z_df = pd.DataFrame({'SUBJECT_ID' : z})\n",
    "z_df = z_df.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "heparin_patients = pd.merge(heparin_patients, z_df, on = 'SUBJECT_ID')\n",
    "print(heparin_patients.shape)\n",
    "print ('Total patients with first dose: ', len(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEASUREMENT TIME (dose to aPTT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>aPTT_TIME</th>\n",
       "      <th>DOSE_TIME</th>\n",
       "      <th>MEASURE_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-22 04:30:00</td>\n",
       "      <td>2101-10-23 08:00:00</td>\n",
       "      <td>-27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-22 12:45:00</td>\n",
       "      <td>2101-10-23 08:00:00</td>\n",
       "      <td>-19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-22 21:15:00</td>\n",
       "      <td>2101-10-23 08:00:00</td>\n",
       "      <td>-10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-23 03:45:00</td>\n",
       "      <td>2101-10-23 08:00:00</td>\n",
       "      <td>-4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-23 10:10:00</td>\n",
       "      <td>2101-10-23 08:00:00</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SUBJECT_ID            aPTT_TIME            DOSE_TIME  MEASURE_TIME\n",
       "0          3  2101-10-22 04:30:00  2101-10-23 08:00:00         -27.5\n",
       "1          3  2101-10-22 12:45:00  2101-10-23 08:00:00         -19.2\n",
       "2          3  2101-10-22 21:15:00  2101-10-23 08:00:00         -10.8\n",
       "3          3  2101-10-23 03:45:00  2101-10-23 08:00:00          -4.2\n",
       "4          3  2101-10-23 10:10:00  2101-10-23 08:00:00           2.2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aPTT = aPTT.rename(columns = {'CHARTTIME': 'aPTT_TIME'})\n",
    "measure_time = aPTT[['SUBJECT_ID', 'aPTT_TIME']].copy()\n",
    "measure_time = pd.merge(measure_time, first_dose, on = 'SUBJECT_ID')\n",
    "\n",
    "doseDate = measure_time['DOSE_TIME']\n",
    "measureDate = measure_time['aPTT_TIME']\n",
    "\n",
    "def get_length (first, second):\n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    first = first.replace('-', ' ')\n",
    "    first = first.replace(':', ' ')\n",
    "    second = second.replace('-', ' ')\n",
    "    second = second.replace(':', ' ')\n",
    "\n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    first = first.split(' ')\n",
    "    second = second.split(' ')\n",
    "\n",
    "    #convert to integers\n",
    "    first = [int(i) for i in first]\n",
    "    second = [int(i) for i in second]\n",
    "    \n",
    "    #get los and return it\n",
    "    first = datetime.datetime(first[0], first[1], first[2], first[3], first[4], first[5])\n",
    "    second = datetime.datetime(second[0], second[1], second[2], second[3], second[4], second[5])\n",
    "    length = (second-first).total_seconds()/3600\n",
    "    length = round(length, 1)\n",
    "\n",
    "    return length\n",
    "\n",
    "measure_list = []\n",
    "\n",
    "for i in range(len(doseDate)):\n",
    "    measure_list.append(get_length(doseDate[i], measureDate[i]))\n",
    "    \n",
    "measure_df = pd.DataFrame({'MEASURE_TIME' : measure_list})\n",
    "measure_time = pd.concat([measure_time, measure_df], axis = 1)\n",
    "measure_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aPTT_dosage = pd.merge(aPTT, measure_time, on = ['SUBJECT_ID', 'aPTT_TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save rows with values between 4 and 10 hours\n",
    "measurements = aPTT_dosage['MEASURE_TIME']\n",
    "\n",
    "def get_measure (time):\n",
    "    if time < 4:\n",
    "        return (None)\n",
    "    if time > 10:\n",
    "        return (None)\n",
    "    else:\n",
    "        return (time)\n",
    "\n",
    "measurements_list = [get_measure(value) for value in measurements]\n",
    "\n",
    "measurements_df = pd.DataFrame({'MEASUREMENT_TIME' : measurements_list})\n",
    "aPTT_dosage = pd.concat([aPTT_dosage, measurements_df], axis = 1)\n",
    "aPTT_dosage = aPTT_dosage.dropna()\n",
    "aPTT_dosage = aPTT_dosage.drop('MEASUREMENT_TIME', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOSAGE TIME (adm to dose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DOSE_TIME</th>\n",
       "      <th>DOSAGE_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>2160-11-02 02:06:00</td>\n",
       "      <td>2160-11-03 10:00:00</td>\n",
       "      <td>31.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>2115-02-20 17:41:00</td>\n",
       "      <td>2115-02-20 20:00:00</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>2119-10-29 14:49:00</td>\n",
       "      <td>2119-10-30 23:00:00</td>\n",
       "      <td>32.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154</td>\n",
       "      <td>2117-12-29 21:36:00</td>\n",
       "      <td>2117-12-29 22:00:00</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>2142-04-24 06:55:00</td>\n",
       "      <td>2142-04-24 21:00:00</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SUBJECT_ID            ADMITTIME            DOSE_TIME  DOSAGE_TIME\n",
       "0         25  2160-11-02 02:06:00  2160-11-03 10:00:00         31.9\n",
       "1        107  2115-02-20 17:41:00  2115-02-20 20:00:00          2.3\n",
       "2        130  2119-10-29 14:49:00  2119-10-30 23:00:00         32.2\n",
       "3        154  2117-12-29 21:36:00  2117-12-29 22:00:00          0.4\n",
       "4        111  2142-04-24 06:55:00  2142-04-24 21:00:00         14.1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adm = patient_times_info[['SUBJECT_ID', 'ADMITTIME']].copy()\n",
    "dosage_info = pd.merge(adm, first_dose, on = 'SUBJECT_ID')\n",
    "\n",
    "admDate = dosage_info['ADMITTIME']\n",
    "doseDate = dosage_info['DOSE_TIME']\n",
    "\n",
    "dosage_list = []\n",
    "\n",
    "for i in range(len(admDate)):\n",
    "    dosage_list.append(get_length(admDate[i], doseDate[i]))\n",
    "    \n",
    "dosage_df = pd.DataFrame({'DOSAGE_TIME' : dosage_list})\n",
    "dosage_time = pd.concat([dosage_info, dosage_df], axis = 1)\n",
    "dosage_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. STROKE PATIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract all ischemic stroke patients from heparin_patients\n",
    "patient_diagnoses = pd.merge(diagnoses, dir_diagnoses, on = 'ICD9_CODE')\n",
    "patient_diagnoses = patient_diagnoses.drop('ICD9_CODE', axis = 1)\n",
    "patient_diagnoses['HADM_ID'] = patient_diagnoses['HADM_ID'].apply(str)\n",
    "patient_diagnoses = patient_diagnoses.reset_index(drop = True)\n",
    "\n",
    "word_list = ['STROKE', 'CVA', 'CEREBROVASCULAR ACCIDENT']\n",
    "STROKE_diagnosis = heparin_patients[heparin_patients['DIAGNOSIS'].str.contains('|'.join(word_list))]\n",
    "    #97 TOTAL STROKE\n",
    "\n",
    "word_list = ['TIA', 'TRANSIENT ISCHEMIC ATTACK']\n",
    "TIA_diagnosis = STROKE_diagnosis[STROKE_diagnosis['DIAGNOSIS'].str.contains('|'.join(word_list))]\n",
    "    #53 TOTAL TIA\n",
    "    \n",
    "word_list = TIA_diagnosis['SUBJECT_ID'].tolist()\n",
    "STROKE_diagnosis = STROKE_diagnosis.set_index(STROKE_diagnosis['SUBJECT_ID'])\n",
    "ISCHEMIC_STROKE_diagnosis = STROKE_diagnosis.drop(word_list)\n",
    "    #44 TOTAL ISCHEMIC STROKE\n",
    "\n",
    "ISCHEMIC_STROKE_diagnosis['HADM_ID'].apply(str)\n",
    "ISCHEMIC_STROKE_diagnosis = ISCHEMIC_STROKE_diagnosis.reset_index(drop = True)\n",
    "word_list = ISCHEMIC_STROKE_diagnosis['HADM_ID'].tolist()\n",
    "heparin_stroke_info = patient_diagnoses[patient_diagnoses['HADM_ID'].str.contains('|'.join(word_list))]\n",
    "heparin_stroke_info = heparin_stroke_info.sort_values('SUBJECT_ID')\n",
    "\n",
    "    # ISCHEMIC_STROKE_diagnosis contains general information about the patient's stay\n",
    "    # heparin_stroke_info contains specific diagnoses about the patients (did not use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 13)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aPTT_heparin = pd.merge(dosage_time, aPTT_dosage, on = ['SUBJECT_ID', 'DOSE_TIME'])\n",
    "aPTT_heparin = pd.merge(ISCHEMIC_STROKE_diagnosis, aPTT_heparin, on = ['SUBJECT_ID', 'HADM_ID'])\n",
    "aPTT_heparin = aPTT_heparin.drop(['SUBJECT_ID', 'HADM_ID', 'DIAGNOSIS', 'ADMITTIME', 'DOSE_TIME', 'ITEMID', 'aPTT_TIME', 'VALUEUOM', 'LABEL', 'FLUID', 'CATEGORY'], axis = 1)\n",
    "aPTT_heparin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLIT WEEKDAY VS WEEKEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "word_list = ['0', '1', '2', '3']\n",
    "heparin_weekday = aPTT_heparin.loc[aPTT_heparin['ADM_DAY'].isin(word_list)]\n",
    "\n",
    "word_list = ['4', '5', '6']\n",
    "heparin_weekend = aPTT_heparin.loc[aPTT_heparin['ADM_DAY'].isin(word_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 13)\n",
      "(12, 13)\n"
     ]
    }
   ],
   "source": [
    "print(heparin_weekday.shape)\n",
    "print(heparin_weekend.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. WEEKDAY NUMERICAL : Target = MORTALITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LOS', 0),\n",
       " ('DOSAGE_TIME', 1),\n",
       " ('MEASURE_TIME', 2),\n",
       " ('ADMISSION_LOCATION_CLINIC REFERRAL/PREMATURE', 3),\n",
       " ('ADMISSION_LOCATION_EMERGENCY ROOM ADMIT', 4),\n",
       " ('ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI', 5),\n",
       " ('GENDER_F', 6),\n",
       " ('GENDER_M', 7),\n",
       " ('ETHNICITY_NOT WHITE', 8),\n",
       " ('ETHNICITY_WHITE', 9),\n",
       " ('AGE_CAT_50s', 10),\n",
       " ('AGE_CAT_89+', 11),\n",
       " ('AGE_CAT_Elderly', 12),\n",
       " ('DAY_NIGHT_DAY', 13),\n",
       " ('DAY_NIGHT_NIGHT', 14),\n",
       " ('aPTT_CAT_SUB-TH', 15),\n",
       " ('aPTT_CAT_SUPRA-TH', 16),\n",
       " ('aPTT_CAT_TH', 17)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREPROCESSING\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Scale numerical features\n",
    "X_num_day = heparin_weekday[['LOS', 'DOSAGE_TIME', 'MEASURE_TIME']].copy()\n",
    "scaled_X_num_day = pd.DataFrame(normalize(X_num_day), columns=X_num_day.keys())\n",
    "\n",
    "# Combine numerical and categorical values\n",
    "X_cat_day = heparin_weekday[['ADMISSION_LOCATION', 'GENDER', 'ETHNICITY', 'AGE_CAT', 'DAY_NIGHT', 'aPTT_CAT']].copy()\n",
    "X_cat_day = pd.get_dummies(X_cat_day)\n",
    "X_cat_day = X_cat_day.reset_index(drop = True)\n",
    "X_num_day = pd.concat([scaled_X_num_day, X_cat_day], axis = 1)\n",
    "\n",
    "X = X_num_day.as_matrix()\n",
    "\n",
    "y_num_day = heparin_weekday[['EXPIRE_FLAG']].copy()\n",
    "y = y_num_day.as_matrix()\n",
    "\n",
    "column_titles = list(X_num_day)\n",
    "value_map = []\n",
    "for value in range(len(column_titles)):\n",
    "    x = column_titles[value], value\n",
    "    value_map.append(x)\n",
    "value_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 18 artists>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZd52IwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f55bdda82b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.clf()\n",
    "\n",
    "X_indices = np.arange(X.shape[-1])\n",
    "\n",
    "# Plot the feature score map\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "selector.fit(X, y)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "scores /= scores.max()\n",
    "plt.bar(X_indices - .45, scores, width=.2,\n",
    "        label=r'Univariate score ($-Log(p_{value})$)', color='darkorange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOS</td>\n",
       "      <td>0.694776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOSAGE_TIME</td>\n",
       "      <td>0.978926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEASURE_TIME</td>\n",
       "      <td>0.082685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADMISSION_LOCATION_CLINIC REFERRAL/PREMATURE</td>\n",
       "      <td>0.497662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADMISSION_LOCATION_EMERGENCY ROOM ADMIT</td>\n",
       "      <td>0.045010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>0.955136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GENDER_F</td>\n",
       "      <td>0.202010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GENDER_M</td>\n",
       "      <td>0.202010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ETHNICITY_NOT WHITE</td>\n",
       "      <td>0.167510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ETHNICITY_WHITE</td>\n",
       "      <td>0.167510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AGE_CAT_50s</td>\n",
       "      <td>0.292584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AGE_CAT_89+</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AGE_CAT_Elderly</td>\n",
       "      <td>0.167510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DAY_NIGHT_DAY</td>\n",
       "      <td>0.579938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DAY_NIGHT_NIGHT</td>\n",
       "      <td>0.579938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aPTT_CAT_SUB-TH</td>\n",
       "      <td>0.715646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aPTT_CAT_SUPRA-TH</td>\n",
       "      <td>0.180406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aPTT_CAT_TH</td>\n",
       "      <td>0.920311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         FEATURE     SCORE\n",
       "0                                            LOS  0.694776\n",
       "1                                    DOSAGE_TIME  0.978926\n",
       "2                                   MEASURE_TIME  0.082685\n",
       "3   ADMISSION_LOCATION_CLINIC REFERRAL/PREMATURE  0.497662\n",
       "4        ADMISSION_LOCATION_EMERGENCY ROOM ADMIT  0.045010\n",
       "5   ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI  0.955136\n",
       "6                                       GENDER_F  0.202010\n",
       "7                                       GENDER_M  0.202010\n",
       "8                            ETHNICITY_NOT WHITE  0.167510\n",
       "9                                ETHNICITY_WHITE  0.167510\n",
       "10                                   AGE_CAT_50s  0.292584\n",
       "11                                   AGE_CAT_89+  1.000000\n",
       "12                               AGE_CAT_Elderly  0.167510\n",
       "13                                 DAY_NIGHT_DAY  0.579938\n",
       "14                               DAY_NIGHT_NIGHT  0.579938\n",
       "15                               aPTT_CAT_SUB-TH  0.715646\n",
       "16                             aPTT_CAT_SUPRA-TH  0.180406\n",
       "17                                   aPTT_CAT_TH  0.920311"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show feature score map\n",
    "score_map = []\n",
    "for x in range(len(scores)):\n",
    "    x = column_titles[x], scores[x]\n",
    "    score_map.append(x)\n",
    "score_map_df = pd.DataFrame(score_map)\n",
    "score_map_df = score_map_df.rename(columns = {0: 'FEATURE', 1 : 'SCORE'})\n",
    "score_map_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>P-VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOS</td>\n",
       "      <td>0.359636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOSAGE_TIME</td>\n",
       "      <td>0.236712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEASURE_TIME</td>\n",
       "      <td>0.885407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADMISSION_LOCATION_CLINIC REFERRAL/PREMATURE</td>\n",
       "      <td>0.480694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADMISSION_LOCATION_EMERGENCY ROOM ADMIT</td>\n",
       "      <td>0.935896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>0.245147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GENDER_F</td>\n",
       "      <td>0.742787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GENDER_M</td>\n",
       "      <td>0.742787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ETHNICITY_NOT WHITE</td>\n",
       "      <td>0.781482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ETHNICITY_WHITE</td>\n",
       "      <td>0.781482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AGE_CAT_50s</td>\n",
       "      <td>0.650077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AGE_CAT_89+</td>\n",
       "      <td>0.229481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AGE_CAT_Elderly</td>\n",
       "      <td>0.781482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DAY_NIGHT_DAY</td>\n",
       "      <td>0.425866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DAY_NIGHT_NIGHT</td>\n",
       "      <td>0.425866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aPTT_CAT_SUB-TH</td>\n",
       "      <td>0.348756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aPTT_CAT_SUPRA-TH</td>\n",
       "      <td>0.766788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aPTT_CAT_TH</td>\n",
       "      <td>0.258041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         FEATURE   P-VALUE\n",
       "0                                            LOS  0.359636\n",
       "1                                    DOSAGE_TIME  0.236712\n",
       "2                                   MEASURE_TIME  0.885407\n",
       "3   ADMISSION_LOCATION_CLINIC REFERRAL/PREMATURE  0.480694\n",
       "4        ADMISSION_LOCATION_EMERGENCY ROOM ADMIT  0.935896\n",
       "5   ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI  0.245147\n",
       "6                                       GENDER_F  0.742787\n",
       "7                                       GENDER_M  0.742787\n",
       "8                            ETHNICITY_NOT WHITE  0.781482\n",
       "9                                ETHNICITY_WHITE  0.781482\n",
       "10                                   AGE_CAT_50s  0.650077\n",
       "11                                   AGE_CAT_89+  0.229481\n",
       "12                               AGE_CAT_Elderly  0.781482\n",
       "13                                 DAY_NIGHT_DAY  0.425866\n",
       "14                               DAY_NIGHT_NIGHT  0.425866\n",
       "15                               aPTT_CAT_SUB-TH  0.348756\n",
       "16                             aPTT_CAT_SUPRA-TH  0.766788\n",
       "17                                   aPTT_CAT_TH  0.258041"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue_map = []\n",
    "for x in range(len(selector.pvalues_)):\n",
    "    x = column_titles[x], selector.pvalues_[x]\n",
    "    pvalue_map.append(x)\n",
    "pvalue_df = pd.DataFrame(pvalue_map)\n",
    "pvalue_df = pvalue_df.rename(columns = {0: 'FEATURE', 1 : 'P-VALUE'})\n",
    "pvalue_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(15, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-3416222c497d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manova__percentile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Compute cross-validation score using 1 CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mthis_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mscore_means\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mscore_stds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    422\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[0;32m--> 424\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(15, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# SVM-ANOVA\n",
    "from sklearn import svm, datasets, feature_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "transform = feature_selection.SelectPercentile(feature_selection.f_classif)\n",
    "\n",
    "clf = Pipeline([('anova', transform), ('svc', svm.SVC(C=1.0))])\n",
    "\n",
    "print(X.shape)\n",
    "y_list = y.tolist()\n",
    "y_new = []\n",
    "for i in range(len(y_list)):\n",
    "    y_new.append(y_list[i][0])\n",
    "y_array = np.array(y_new)\n",
    "y_array.shape\n",
    "\n",
    "score_means = list()\n",
    "score_stds = list()\n",
    "percentiles = percentiles = (1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100)\n",
    "\n",
    "for percentile in percentiles:\n",
    "    clf.set_params(anova__percentile=percentile)\n",
    "    # Compute cross-validation score using 1 CPU\n",
    "    this_scores = cross_val_score(clf, X, y_array, n_jobs=1)\n",
    "    score_means.append(this_scores.mean())\n",
    "    score_stds.append(this_scores.std())\n",
    "\n",
    "plt.errorbar(percentiles, score_means, np.array(score_stds))\n",
    "\n",
    "plt.title('')\n",
    "plt.xlabel('Percentile')\n",
    "plt.ylabel('Prediction Rate')\n",
    "\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
