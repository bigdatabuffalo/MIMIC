{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# File specific imports\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "rnd.seed(42)\n",
    "\n",
    "# Show all columns when displaying dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (7,17,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/ADMISSIONS.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'ADMISSION_LOCATION', 'ETHNICITY', 'DIAGNOSIS']\n",
    "admissions = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/PATIENTS.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'GENDER', 'DOB', 'EXPIRE_FLAG']\n",
    "patients = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/INPUTEVENTS_CV.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'ORDERID', 'CHARTTIME', 'ITEMID', 'AMOUNT', 'AMOUNTUOM', 'ORIGINALAMOUNT', 'ORIGINALAMOUNTUOM', 'ORIGINALRATE', 'ORIGINALRATEUOM'] # 'RATE', 'RATEUOM', 'STOPPED' are full of NaN\n",
    "inputevents_cv = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/INPUTEVENTS_MV.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'ORDERID', 'STARTTIME', 'ENDTIME', 'ITEMID', 'AMOUNT', 'AMOUNTUOM', 'RATE', 'RATEUOM', 'ORDERCATEGORYNAME', 'ORDERCATEGORYDESCRIPTION']\n",
    "inputevents_mv = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/LABEVENTS.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'HADM_ID', 'ITEMID', 'CHARTTIME', 'VALUE', 'VALUENUM', 'VALUEUOM', 'FLAG'] # 'HADM_ID' is full of NaN\n",
    "labevents = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/D_ITEMS.csv'\n",
    "cols_to_keep = ['ITEMID', 'LABEL'] #'CATEGORY', 'UNITNAME', 'PARAM_TYPE' are full of NaN\n",
    "d_items = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/D_LABITEMS.csv'\n",
    "cols_to_keep = ['ITEMID', 'LABEL', 'FLUID', 'CATEGORY']\n",
    "d_labitems = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "admissions = admissions.applymap(str)\n",
    "patients = patients.applymap(str)\n",
    "inputevents_cv = inputevents_cv.applymap(str)\n",
    "inputevents_mv  = inputevents_mv.applymap(str)\n",
    "labevents  = labevents.applymap(str) \n",
    "d_items = d_items.applymap(str)\n",
    "d_labitems = d_labitems.applymap(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATIENT INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine admissions and patients\n",
    "patient_info = pd.merge(admissions, patients, on = ['SUBJECT_ID'])\n",
    "\n",
    "# Change Ethnicity to White/Non-White\n",
    "ethnicity = patient_info['ETHNICITY']\n",
    "\n",
    "def get_ethnicity(value):\n",
    "    if value == 'WHITE':\n",
    "        return 'WHITE'\n",
    "    else:\n",
    "        return 'NOT WHITE'\n",
    "\n",
    "list_ethnicity = [get_ethnicity(value) for value in ethnicity]\n",
    "\n",
    "patient_info = patient_info.drop('ETHNICITY', axis = 1)\n",
    "df_ethnicity = pd.DataFrame({'ETHNICITY' : list_ethnicity})\n",
    "patient_info = pd.concat([patient_info, df_ethnicity], axis=1)\n",
    "\n",
    "# Add ages\n",
    "DoB = patient_info['DOB']\n",
    "admDate = patient_info['ADMITTIME']\n",
    "\n",
    "def get_age (birth, current):\n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    birth = birth.replace('-', ' ')\n",
    "    birth = birth.replace(':', ' ')\n",
    "    current = current.replace('-', ' ')\n",
    "    current = current.replace(':', ' ')\n",
    "\n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    birth = birth.split(' ')\n",
    "    current = current.split(' ')\n",
    "\n",
    "    #convert to integers\n",
    "    birth = [int(i) for i in birth]\n",
    "    current = [int(i) for i in current]\n",
    "    \n",
    "    #get age and return it\n",
    "    birth = datetime.datetime(birth[0], birth[1], birth[2], birth[3], birth[4], birth[5])\n",
    "    current = datetime.datetime(current[0], current[1], current[2], current[3], current[4], current[5])\n",
    "    age = relativedelta(current, birth).years\n",
    "    \n",
    "    #adjust for 89+ category\n",
    "    if age == 300:\n",
    "        age = 89\n",
    "    \n",
    "    return age\n",
    "\n",
    "def get_age_category(age):\n",
    "    if age > 88:\n",
    "        return ('89+')\n",
    "    elif age > 60:\n",
    "        return('Elderly')\n",
    "    elif age > 50:\n",
    "        return('50s')\n",
    "    elif age > 40:\n",
    "        return('40s')\n",
    "    elif age > 30:\n",
    "        return('30s')\n",
    "    elif age > 17:\n",
    "        return('20s')\n",
    "    else:\n",
    "        return('Child')\n",
    "\n",
    "ages = []\n",
    "age_categories = []\n",
    "\n",
    "for i in range(len(DoB)):\n",
    "    ages.append(get_age(DoB[i], admDate[i]))\n",
    "\n",
    "for age in ages:\n",
    "    age_categories.append(get_age_category(age))\n",
    "\n",
    "ages_df = pd.DataFrame({'AGE' : ages})\n",
    "ages_cat_df = pd.DataFrame({'AGE_CAT' : age_categories})\n",
    "patient_info = pd.concat([patient_info, ages_df], axis=1)\n",
    "patient_info = pd.concat([patient_info, ages_cat_df], axis=1)\n",
    "\n",
    "# Add LOS\n",
    "admDate = patient_info['ADMITTIME']\n",
    "dischDate = patient_info['DISCHTIME']\n",
    "\n",
    "def get_los (admit, disch):\n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    admit = admit.replace('-', ' ')\n",
    "    admit = admit.replace(':', ' ')\n",
    "    disch = disch.replace('-', ' ')\n",
    "    disch = disch.replace(':', ' ')\n",
    "\n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    admit = admit.split(' ')\n",
    "    disch = disch.split(' ')\n",
    "\n",
    "    #convert to integers\n",
    "    admit = [int(i) for i in admit]\n",
    "    disch = [int(i) for i in disch]\n",
    "    \n",
    "    #get los and return it\n",
    "    admit = datetime.datetime(admit[0], admit[1], admit[2], admit[3], admit[4], admit[5])\n",
    "    disch = datetime.datetime(disch[0], disch[1], disch[2], disch[3], disch[4], disch[5])\n",
    "    los = (disch-admit).total_seconds()/3600\n",
    "    los = round((los/24), 1)\n",
    "\n",
    "    return los\n",
    "\n",
    "los = []\n",
    "\n",
    "for i in range(len(admDate)):\n",
    "    los.append(get_los(admDate[i], dischDate[i]))\n",
    "    \n",
    "los_df = pd.DataFrame({'LOS' : los})\n",
    "patient_info = pd.concat([patient_info, los_df], axis = 1)\n",
    "\n",
    "# Get Day/Night (day is between 8 am : 8 pm)\n",
    "admTime = patient_info['ADMITTIME']\n",
    "\n",
    "def get_day_night (value):\n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    value = value.replace('-', ' ')\n",
    "    value = value.replace(':', ' ')\n",
    "    \n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    date = value.split(' ')\n",
    "    \n",
    "    #leave hour/min/sec, convert to integers\n",
    "    hour = date[3]\n",
    "    int_hour = int(hour)\n",
    "    \n",
    "    #get day/night and return it\n",
    "    if 7 < int_hour < 21:\n",
    "        return 'DAY'\n",
    "    else:\n",
    "        return 'NIGHT'\n",
    "\n",
    "day_night = [get_day_night(value) for value in admTime]\n",
    "\n",
    "day_night_df = pd.DataFrame({'DAY_NIGHT' : day_night})\n",
    "patient_info = pd.concat([patient_info, day_night_df], axis=1)\n",
    "\n",
    "# Get admission day\n",
    "admTime = patient_info['ADMITTIME']\n",
    "\n",
    "def get_day_of_week (value):\n",
    "    date = []\n",
    "    int_date = []\n",
    "    day_of_week = []\n",
    "    \n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    value = value.replace('-', ' ')\n",
    "    value = value.replace(':', ' ')\n",
    "    \n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    date = value.split(' ')\n",
    "    \n",
    "    #delete hour/min/sec, convert to integers\n",
    "    del date[3:6]\n",
    "    int_date = [int(i) for i in date]\n",
    "    \n",
    "    #get day of week and return it\n",
    "    day_of_week = datetime.date(int_date[0], int_date[1], int_date[2]).weekday()\n",
    "    \n",
    "    return day_of_week\n",
    "\n",
    "\n",
    "admTime_weekday = [get_day_of_week(value) for value in admTime]\n",
    "\n",
    "weekday_data_df = pd.DataFrame({'ADM_DAY' : admTime_weekday})\n",
    "patient_info = pd.concat([patient_info, weekday_data_df], axis=1)\n",
    "\n",
    "# Clean up columns\n",
    "patient_times_info = patient_info[['SUBJECT_ID', 'ADMITTIME', 'DISCHTIME', 'DOB']].copy()\n",
    "patient_times_info = patient_times_info.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "\n",
    "patient_info = patient_info.drop(['ADMITTIME', 'DISCHTIME', 'DOB'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LABEVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert labevents[FLAG] : NaN to 0, abnomal to 1\n",
    "labevents['FLAG'] = labevents['FLAG'].replace('nan', 0)\n",
    "labevents['FLAG'] = labevents['FLAG'].replace('abnormal', 1)\n",
    "\n",
    "# Merge d_labitems onto labevents \n",
    "labevents = pd.merge(labevents, d_labitems, on = 'ITEMID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUTEVENTS (CV AND MV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge d_items onto inputevents_cv, and inputevents_mv separately\n",
    "inputevents_cv = pd.merge(inputevents_cv, d_items, on = 'ITEMID')\n",
    "inputevents_mv = pd.merge(inputevents_mv, d_items, on = 'ITEMID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heparin Data Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMISSION_LOCATION</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>EXPIRE_FLAG</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGE_CAT</th>\n",
       "      <th>LOS</th>\n",
       "      <th>DAY_NIGHT</th>\n",
       "      <th>ADM_DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>165315</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>BENZODIAZEPINE OVERDOSE</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>64</td>\n",
       "      <td>Elderly</td>\n",
       "      <td>1.1</td>\n",
       "      <td>DAY</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>152223</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>CORONARY ARTERY DISEASE\\CORONARY ARTERY BYPASS...</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>71</td>\n",
       "      <td>Elderly</td>\n",
       "      <td>5.5</td>\n",
       "      <td>NIGHT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>124321</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>BRAIN MASS</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>75</td>\n",
       "      <td>Elderly</td>\n",
       "      <td>6.8</td>\n",
       "      <td>DAY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>161859</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>INTERIOR MYOCARDIAL INFARCTION</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>39</td>\n",
       "      <td>30s</td>\n",
       "      <td>2.9</td>\n",
       "      <td>DAY</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>129635</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>ACUTE CORONARY SYNDROME</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>58</td>\n",
       "      <td>50s</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NIGHT</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SUBJECT_ID HADM_ID         ADMISSION_LOCATION  \\\n",
       "0         22  165315       EMERGENCY ROOM ADMIT   \n",
       "1         23  152223  PHYS REFERRAL/NORMAL DELI   \n",
       "2         23  124321  TRANSFER FROM HOSP/EXTRAM   \n",
       "3         24  161859  TRANSFER FROM HOSP/EXTRAM   \n",
       "4         25  129635       EMERGENCY ROOM ADMIT   \n",
       "\n",
       "                                           DIAGNOSIS GENDER EXPIRE_FLAG  \\\n",
       "0                            BENZODIAZEPINE OVERDOSE      F           0   \n",
       "1  CORONARY ARTERY DISEASE\\CORONARY ARTERY BYPASS...      M           0   \n",
       "2                                         BRAIN MASS      M           0   \n",
       "3                     INTERIOR MYOCARDIAL INFARCTION      M           0   \n",
       "4                            ACUTE CORONARY SYNDROME      M           0   \n",
       "\n",
       "  ETHNICITY  AGE  AGE_CAT  LOS DAY_NIGHT  ADM_DAY  \n",
       "0     WHITE   64  Elderly  1.1       DAY        5  \n",
       "1     WHITE   71  Elderly  5.5     NIGHT        0  \n",
       "2     WHITE   75  Elderly  6.8       DAY        1  \n",
       "3     WHITE   39      30s  2.9       DAY        5  \n",
       "4     WHITE   58      50s  3.5     NIGHT        6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. UNIQUE ADULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PT recieving UFH:  8095\n"
     ]
    }
   ],
   "source": [
    "# Get only first ICU stay for each patient\n",
    "patient_info = patient_info.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "\n",
    "# Find all Heparin patients\n",
    "word_list = ['Heparin']\n",
    "heparin_cv = inputevents_cv.loc[inputevents_cv['LABEL'].isin(word_list)]\n",
    "heparin_mv = inputevents_mv[inputevents_mv['LABEL'].str.contains('|'.join(word_list))]\n",
    "\n",
    "# Drop Prophylaxis from heparin_mv\n",
    "heparin_mv = heparin_mv[heparin_mv['LABEL'] != 'Heparin Sodium (Prophylaxis)']\n",
    "\n",
    "# Count total patients recieving UFH\n",
    "gp_cv = heparin_cv['SUBJECT_ID'].unique().tolist()\n",
    "gp_mv = heparin_mv['SUBJECT_ID'].unique().tolist()\n",
    "patient_count = len(gp_cv) + len(gp_mv)\n",
    "print('Total PT recieving UFH: ', patient_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7974, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update patient_info to heparin_patients\n",
    "patient_list = gp_cv + gp_mv\n",
    "\n",
    "heparin_patients = pd.DataFrame({'SUBJECT_ID' : patient_list})\n",
    "heparin_patients = heparin_patients.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "heparin_patients = pd.merge(heparin_patients, patient_info, on = 'SUBJECT_ID')\n",
    "heparin_patients.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. aPTT MEASUREMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PT with aPTT tests:  4195\n"
     ]
    }
   ],
   "source": [
    "# Find all aPTT measurements\n",
    "word_list = ['PTT']\n",
    "aPTT = labevents[labevents['LABEL'].str.contains('|'.join(word_list))]\n",
    "aPTT = aPTT.reset_index(drop = True)\n",
    "aPTT['HADM_ID'] = aPTT['HADM_ID'].str.replace('.0', '')\n",
    "\n",
    "# Remove repeat HADM_ID\n",
    "word_list = heparin_patients['HADM_ID'].tolist()\n",
    "aPTT = aPTT.loc[aPTT['HADM_ID'].isin(word_list)]\n",
    "\n",
    "# Create Groups\n",
    "gp_ptt = aPTT['SUBJECT_ID'].unique().tolist()\n",
    "patient_count = len(gp_ptt)\n",
    "\n",
    "print('Total PT with aPTT tests: ', patient_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4195, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update heparin_patients\n",
    "patient_list_ptt = gp_ptt\n",
    "aPTT_patients = pd.DataFrame({'SUBJECT_ID' : patient_list_ptt})\n",
    "heparin_patients = pd.merge(heparin_patients, aPTT_patients, on = 'SUBJECT_ID')\n",
    "heparin_patients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptts = aPTT['VALUE']\n",
    "\n",
    "def get_aPTT(ptt):\n",
    "    if ptt == '>150':\n",
    "        return ('150.0')\n",
    "    elif ptt == '>150.0':\n",
    "        return ('150.0')\n",
    "    elif ptt == '> 150':\n",
    "        return ('150.0')\n",
    "    elif len(ptt) > 5:\n",
    "        return (None)\n",
    "    elif ptt == 'ERROR':\n",
    "        return (None)\n",
    "    ptt = ptt.replace('..', '.')\n",
    "    return(ptt)\n",
    "\n",
    "def get_aPTT_category(ptt):\n",
    "    if ptt == None:\n",
    "        return (None)\n",
    "    ptt = float(ptt)\n",
    "    if ptt > 100:\n",
    "        return ('SUPRA-TH')\n",
    "    elif ptt < 60:\n",
    "        return('SUB-TH')\n",
    "    else:\n",
    "        return('TH')\n",
    "\n",
    "ptts_new = []\n",
    "ptt_categories = []\n",
    "\n",
    "for ptt in ptts:\n",
    "    ptts_new.append(get_aPTT(ptt))\n",
    "\n",
    "for ptt in ptts_new:\n",
    "    ptt_categories.append(get_aPTT_category(ptt))\n",
    "\n",
    "ptt_df = pd.DataFrame({'aPTT' : ptts_new})\n",
    "ptt_cat_df = pd.DataFrame({'aPTT_CAT' : ptt_categories})\n",
    "\n",
    "aPTT = aPTT.reset_index(drop = True)\n",
    "aPTT = pd.concat([aPTT, ptt_df], axis = 1)\n",
    "aPTT = pd.concat([aPTT, ptt_cat_df], axis = 1)\n",
    "aPTT = aPTT[['SUBJECT_ID', 'HADM_ID', 'ITEMID', 'CHARTTIME', 'aPTT', 'VALUEUOM', 'LABEL', 'aPTT_CAT', 'FLUID', 'CATEGORY']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. NON TRANSFERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2914, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heparin_patients = heparin_patients[heparin_patients.ADMISSION_LOCATION != 'TRANSFER FROM SKILLED NUR']\n",
    "heparin_patients = heparin_patients[heparin_patients.ADMISSION_LOCATION != 'TRANSFER FROM HOSP/EXTRAM']\n",
    "heparin_patients = heparin_patients[heparin_patients.ADMISSION_LOCATION != 'TRANSFER FROM OTHER HEALT']\n",
    "heparin_patients = heparin_patients[heparin_patients.ADMISSION_LOCATION != '** INFO NOT AVAILABLE **']\n",
    "\n",
    "heparin_patients.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dosage Start Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2440, 12)\n",
      "Total patients with first dose:  2440\n"
     ]
    }
   ],
   "source": [
    "# Update heparin dosage dataframes\n",
    "word_list = heparin_patients['HADM_ID'].tolist()\n",
    "heparin_cv['HADM_ID'] = heparin_cv['HADM_ID'].str.replace('.0', '')\n",
    "heparin_cv = heparin_cv.loc[heparin_cv['HADM_ID'].isin(word_list)]\n",
    "heparin_mv = heparin_mv.loc[heparin_mv['HADM_ID'].isin(word_list)]\n",
    "\n",
    "# Extract IDs and Start Times\n",
    "dose_cv = heparin_cv[['SUBJECT_ID', 'CHARTTIME']].copy()\n",
    "dose_cv = dose_cv.rename(columns = {'CHARTTIME': 'DOSE_TIME'})\n",
    "\n",
    "dose_mv = heparin_mv[['SUBJECT_ID', 'STARTTIME']].copy()\n",
    "dose_mv = dose_mv.rename(columns = {'STARTTIME': 'DOSE_TIME'})\n",
    "\n",
    "# Combine and take First Dose\n",
    "dose_info = pd.concat([dose_cv, dose_mv])\n",
    "first_dose = dose_info.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "\n",
    "#Update patient numbers\n",
    "x = heparin_cv['SUBJECT_ID'].unique().tolist()\n",
    "y = heparin_mv['SUBJECT_ID'].unique().tolist()\n",
    "z = x+y\n",
    "z_df = pd.DataFrame({'SUBJECT_ID' : z})\n",
    "z_df = z_df.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "heparin_patients = pd.merge(heparin_patients, z_df, on = 'SUBJECT_ID')\n",
    "print(heparin_patients.shape)\n",
    "print ('Total patients with first dose: ', len(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEASUREMENT TIME (dose to aPTT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>aPTT_TIME</th>\n",
       "      <th>DOSE_TIME</th>\n",
       "      <th>MEASURE_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-22 04:30:00</td>\n",
       "      <td>2101-10-23 08:00:00</td>\n",
       "      <td>-27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-22 12:45:00</td>\n",
       "      <td>2101-10-23 08:00:00</td>\n",
       "      <td>-19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-22 21:15:00</td>\n",
       "      <td>2101-10-23 08:00:00</td>\n",
       "      <td>-10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-23 03:45:00</td>\n",
       "      <td>2101-10-23 08:00:00</td>\n",
       "      <td>-4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2101-10-23 10:10:00</td>\n",
       "      <td>2101-10-23 08:00:00</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SUBJECT_ID            aPTT_TIME            DOSE_TIME  MEASURE_TIME\n",
       "0          3  2101-10-22 04:30:00  2101-10-23 08:00:00         -27.5\n",
       "1          3  2101-10-22 12:45:00  2101-10-23 08:00:00         -19.2\n",
       "2          3  2101-10-22 21:15:00  2101-10-23 08:00:00         -10.8\n",
       "3          3  2101-10-23 03:45:00  2101-10-23 08:00:00          -4.2\n",
       "4          3  2101-10-23 10:10:00  2101-10-23 08:00:00           2.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aPTT = aPTT.rename(columns = {'CHARTTIME': 'aPTT_TIME'})\n",
    "measure_time = aPTT[['SUBJECT_ID', 'aPTT_TIME']].copy()\n",
    "measure_time = pd.merge(measure_time, first_dose, on = 'SUBJECT_ID')\n",
    "\n",
    "doseDate = measure_time['DOSE_TIME']\n",
    "measureDate = measure_time['aPTT_TIME']\n",
    "\n",
    "def get_length (first, second):\n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    first = first.replace('-', ' ')\n",
    "    first = first.replace(':', ' ')\n",
    "    second = second.replace('-', ' ')\n",
    "    second = second.replace(':', ' ')\n",
    "\n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    first = first.split(' ')\n",
    "    second = second.split(' ')\n",
    "\n",
    "    #convert to integers\n",
    "    first = [int(i) for i in first]\n",
    "    second = [int(i) for i in second]\n",
    "    \n",
    "    #get los and return it\n",
    "    first = datetime.datetime(first[0], first[1], first[2], first[3], first[4], first[5])\n",
    "    second = datetime.datetime(second[0], second[1], second[2], second[3], second[4], second[5])\n",
    "    length = (second-first).total_seconds()/3600\n",
    "    length = round(length, 1)\n",
    "\n",
    "    return length\n",
    "\n",
    "measure_list = []\n",
    "\n",
    "for i in range(len(doseDate)):\n",
    "    measure_list.append(get_length(doseDate[i], measureDate[i]))\n",
    "    \n",
    "measure_df = pd.DataFrame({'MEASURE_TIME' : measure_list})\n",
    "measure_time = pd.concat([measure_time, measure_df], axis = 1)\n",
    "measure_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aPTT_dosage = pd.merge(aPTT, measure_time, on = ['SUBJECT_ID', 'aPTT_TIME'])\n",
    "\n",
    "# Save rows with values between 4 and 10 hours\n",
    "measurements = aPTT_dosage['MEASURE_TIME']\n",
    "\n",
    "def get_measure (time):\n",
    "    if time < 4:\n",
    "        return (None)\n",
    "    if time > 10:\n",
    "        return (None)\n",
    "    else:\n",
    "        return (time)\n",
    "\n",
    "measurements_list = [get_measure(value) for value in measurements]\n",
    "\n",
    "measurements_df = pd.DataFrame({'MEASUREMENT_TIME' : measurements_list})\n",
    "aPTT_dosage = pd.concat([aPTT_dosage, measurements_df], axis = 1)\n",
    "aPTT_dosage = aPTT_dosage.dropna()\n",
    "aPTT_dosage = aPTT_dosage.drop('MEASUREMENT_TIME', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOSAGE TIME (adm to dose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DOSE_TIME</th>\n",
       "      <th>DOSAGE_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>2160-11-02 02:06:00</td>\n",
       "      <td>2160-11-03 10:00:00</td>\n",
       "      <td>31.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>2115-02-20 17:41:00</td>\n",
       "      <td>2115-02-20 20:00:00</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>2119-10-29 14:49:00</td>\n",
       "      <td>2119-10-30 23:00:00</td>\n",
       "      <td>32.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154</td>\n",
       "      <td>2117-12-29 21:36:00</td>\n",
       "      <td>2117-12-29 22:00:00</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>2142-04-24 06:55:00</td>\n",
       "      <td>2142-04-24 21:00:00</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SUBJECT_ID            ADMITTIME            DOSE_TIME  DOSAGE_TIME\n",
       "0         25  2160-11-02 02:06:00  2160-11-03 10:00:00         31.9\n",
       "1        107  2115-02-20 17:41:00  2115-02-20 20:00:00          2.3\n",
       "2        130  2119-10-29 14:49:00  2119-10-30 23:00:00         32.2\n",
       "3        154  2117-12-29 21:36:00  2117-12-29 22:00:00          0.4\n",
       "4        111  2142-04-24 06:55:00  2142-04-24 21:00:00         14.1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adm = patient_times_info[['SUBJECT_ID', 'ADMITTIME']].copy()\n",
    "dosage_info = pd.merge(adm, first_dose, on = 'SUBJECT_ID')\n",
    "\n",
    "admDate = dosage_info['ADMITTIME']\n",
    "doseDate = dosage_info['DOSE_TIME']\n",
    "\n",
    "dosage_list = []\n",
    "\n",
    "for i in range(len(admDate)):\n",
    "    dosage_list.append(get_length(admDate[i], doseDate[i]))\n",
    "    \n",
    "dosage_df = pd.DataFrame({'DOSAGE_TIME' : dosage_list})\n",
    "dosage_time = pd.concat([dosage_info, dosage_df], axis = 1)\n",
    "dosage_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIAL HEPARIN DRIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label 'Heparin' is going to be the focus because it is already in Units\n",
    "word_list = ['Heparin']\n",
    "heparin_units_cv = heparin_cv[heparin_cv['LABEL'].isin(word_list)]\n",
    "\n",
    "heparin_units_mv = heparin_mv.copy()\n",
    "\n",
    "# Clean up\n",
    "heparin_units_cv = heparin_units_cv[heparin_units_cv.ORIGINALRATE != 'nan']\n",
    "heparin_units_cv = heparin_units_cv.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "heparin_units_cv = heparin_units_cv[['SUBJECT_ID', 'CHARTTIME', 'ORIGINALRATE']].copy()\n",
    "heparin_units_cv = heparin_units_cv.rename(columns = {'CHARTTIME': 'STARTTIME'})\n",
    "heparin_units_cv = heparin_units_cv.rename(columns = {'ORIGINALRATE': 'RATE'})\n",
    "heparin_units_cv.RATE = heparin_units_cv.RATE.astype(float)\n",
    "heparin_units_cv.loc[:, 'RATE'] *= 100\n",
    "\n",
    "heparin_units_mv = heparin_units_mv[heparin_units_mv.RATE != 'nan']\n",
    "heparin_units_mv = heparin_units_mv.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "heparin_units_mv = heparin_units_mv[['SUBJECT_ID', 'STARTTIME', 'RATE']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1409, 12)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine into one dataframe\n",
    "heparin_units = pd.concat([heparin_units_cv, heparin_units_mv])\n",
    "heparin_units['RATE'] = pd.to_numeric(heparin_units['RATE']).astype(int)\n",
    "\n",
    "# Update heparin_patients\n",
    "patient_list_units = list(heparin_units['SUBJECT_ID'].unique())\n",
    "units_patients = pd.DataFrame({'SUBJECT_ID' : patient_list_units})\n",
    "heparin_patients = pd.merge(units_patients, heparin_patients, on = 'SUBJECT_ID')\n",
    "heparin_patients.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RATE</th>\n",
       "      <th>ADMISSION_LOCATION</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>EXPIRE_FLAG</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGE_CAT</th>\n",
       "      <th>LOS</th>\n",
       "      <th>DAY_NIGHT</th>\n",
       "      <th>ADM_DAY</th>\n",
       "      <th>DOSAGE_TIME</th>\n",
       "      <th>aPTT</th>\n",
       "      <th>aPTT_CAT</th>\n",
       "      <th>MEASURE_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>89</td>\n",
       "      <td>89+</td>\n",
       "      <td>14.9</td>\n",
       "      <td>DAY</td>\n",
       "      <td>2</td>\n",
       "      <td>191.0</td>\n",
       "      <td>74.1</td>\n",
       "      <td>TH</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>83</td>\n",
       "      <td>Elderly</td>\n",
       "      <td>54.7</td>\n",
       "      <td>DAY</td>\n",
       "      <td>4</td>\n",
       "      <td>5.8</td>\n",
       "      <td>60.4</td>\n",
       "      <td>TH</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>64</td>\n",
       "      <td>Elderly</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NIGHT</td>\n",
       "      <td>1</td>\n",
       "      <td>77.1</td>\n",
       "      <td>150</td>\n",
       "      <td>SUPRA-TH</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>800</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>44</td>\n",
       "      <td>40s</td>\n",
       "      <td>2.7</td>\n",
       "      <td>NIGHT</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>47.5</td>\n",
       "      <td>SUB-TH</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>57</td>\n",
       "      <td>50s</td>\n",
       "      <td>4.8</td>\n",
       "      <td>DAY</td>\n",
       "      <td>4</td>\n",
       "      <td>14.8</td>\n",
       "      <td>150</td>\n",
       "      <td>SUPRA-TH</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RATE    ADMISSION_LOCATION GENDER EXPIRE_FLAG ETHNICITY  AGE  AGE_CAT  \\\n",
       "0   900  EMERGENCY ROOM ADMIT      M           1     WHITE   89      89+   \n",
       "1  1000  EMERGENCY ROOM ADMIT      M           1     WHITE   83  Elderly   \n",
       "2   900  EMERGENCY ROOM ADMIT      F           1     WHITE   64  Elderly   \n",
       "3   800  EMERGENCY ROOM ADMIT      M           0     WHITE   44      40s   \n",
       "4  1000  EMERGENCY ROOM ADMIT      F           1     WHITE   57      50s   \n",
       "\n",
       "    LOS DAY_NIGHT  ADM_DAY  DOSAGE_TIME  aPTT  aPTT_CAT  MEASURE_TIME  \n",
       "0  14.9       DAY        2        191.0  74.1        TH           4.0  \n",
       "1  54.7       DAY        4          5.8  60.4        TH           4.0  \n",
       "2   6.9     NIGHT        1         77.1   150  SUPRA-TH           5.8  \n",
       "3   2.7     NIGHT        2          0.4  47.5    SUB-TH           5.0  \n",
       "4   4.8       DAY        4         14.8   150  SUPRA-TH           6.5  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge dosage, measure, and patient information\n",
    "aPTT_heparin = pd.merge(dosage_time, aPTT_dosage, on = ['SUBJECT_ID', 'DOSE_TIME'])\n",
    "aPTT_heparin = pd.merge(heparin_patients, aPTT_heparin, on = ['SUBJECT_ID', 'HADM_ID'])\n",
    "aPTT_heparin = pd.merge(heparin_units, aPTT_heparin, on = ['SUBJECT_ID'])\n",
    "aPTT_heparin = aPTT_heparin.drop(['SUBJECT_ID', 'HADM_ID', 'STARTTIME', 'DIAGNOSIS', 'ADMITTIME', 'DOSE_TIME', 'ITEMID', 'aPTT_TIME', 'VALUEUOM', 'LABEL', 'FLUID', 'CATEGORY'], axis = 1)\n",
    "aPTT_heparin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLIT WEEKDAY VS WEEKEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list = ['0', '1', '2', '3']\n",
    "heparin_weekday = aPTT_heparin.loc[aPTT_heparin['ADM_DAY'].isin(word_list)]\n",
    "\n",
    "word_list = ['4', '5', '6']\n",
    "heparin_weekend = aPTT_heparin.loc[aPTT_heparin['ADM_DAY'].isin(word_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. WEEKDAY CATEGORIES : Target = aPTT_CAT\n",
    "\n",
    "data_manipulation = heparin_weekday[['ADMISSION_LOCATION', 'GENDER', 'ETHNICITY', 'AGE_CAT', 'DAY_NIGHT', 'EXPIRE_FLAG', 'aPTT_CAT']].copy()\n",
    "data_manipulation['aPTT_CAT'] = data_manipulation['aPTT_CAT'].replace('SUB-TH', '1')\n",
    "data_manipulation['aPTT_CAT'] = data_manipulation['aPTT_CAT'].replace('TH', '0')\n",
    "data_manipulation['aPTT_CAT'] = data_manipulation['aPTT_CAT'].replace('SUPRA-TH', '0')\n",
    "\n",
    "X_num_day = heparin_weekday[['AGE', 'LOS', 'DOSAGE_TIME', 'MEASURE_TIME']].copy()\n",
    "X_num_day = X_num_day.applymap(int)\n",
    "\n",
    "X_cat_day = data_manipulation[['ADMISSION_LOCATION', 'GENDER', 'ETHNICITY', 'EXPIRE_FLAG']].copy() # removed 'AGE_CAT', 'DAY_NIGHT',\n",
    "X_cat_day['EXPIRE_FLAG'] = X_cat_day['EXPIRE_FLAG'].astype(int)\n",
    "X_cat_day = pd.get_dummies(X_cat_day)\n",
    "X_weekday = pd.concat([X_cat_day, X_num_day], axis = 1)\n",
    "\n",
    "X = X_weekday.as_matrix()\n",
    "\n",
    "y = data_manipulation[['aPTT_CAT']].copy()\n",
    "y = y_cat_day.as_matrix()\n",
    "\n",
    "column_titles = list(X_weekday)\n",
    "value_map = []\n",
    "for value in range(len(column_titles)):\n",
    "    x = column_titles[value], value\n",
    "    value_map.append(x)\n",
    "value_map\n",
    "\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "\n",
    "X_indices = np.arange(X.shape[-1])\n",
    "X_indices\n",
    "\n",
    "# Plot the feature score map\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "selector.fit(X, y)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "scores /= scores.max()\n",
    "plt.bar(X_indices - .45, scores, width=.2,\n",
    "        label=r'Univariate score ($-Log(p_{value})$)', color='darkorange')\n",
    "\n",
    "# Show feature score map\n",
    "score_map = []\n",
    "for x in range(len(scores)):\n",
    "    x = column_titles[x], scores[x]\n",
    "    score_map.append(x)\n",
    "score_map_df = pd.DataFrame(score_map)\n",
    "score_map_df = score_map_df.rename(columns = {0: 'FEATURE', 1 : 'SCORE'})\n",
    "score_map_df\n",
    "\n",
    "pvalue_map = []\n",
    "for x in range(len(selector.pvalues_)):\n",
    "    x = column_titles[x], selector.pvalues_[x]\n",
    "    pvalue_map.append(x)\n",
    "pvalue_df = pd.DataFrame(pvalue_map)\n",
    "pvalue_df = pvalue_df.rename(columns = {0: 'FEATURE', 1 : 'P-VALUE'})\n",
    "pvalue_df\n",
    "\n",
    "#SVC\n",
    "from sklearn import datasets, svm\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X, y)\n",
    "\n",
    "svm_weights = (clf.coef_ ** 2).sum(axis=0)\n",
    "svm_weights /= svm_weights.max()\n",
    "\n",
    "plt.bar(X_indices - .25, svm_weights, width=.2, label='SVM weight',\n",
    "        color='navy')\n",
    "\n",
    "clf_selected = svm.SVC(kernel='linear')\n",
    "clf_selected.fit(selector.transform(X), y)\n",
    "\n",
    "svm_weights_selected = (clf_selected.coef_ ** 2).sum(axis=0)\n",
    "svm_weights_selected /= svm_weights_selected.max()\n",
    "\n",
    "plt.bar(X_indices[selector.get_support()] - .05, svm_weights_selected,\n",
    "        width=.2, label='SVM weights after selection', color='c')\n",
    "\n",
    "\n",
    "plt.title(\"Comparing feature selection\")\n",
    "plt.xlabel('Feature number')\n",
    "plt.yticks(())\n",
    "plt.axis('tight')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# SVM-ANOVA\n",
    "from sklearn import svm, datasets, feature_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "transform = feature_selection.SelectPercentile(feature_selection.f_classif)\n",
    "\n",
    "clf = Pipeline([('anova', transform), ('svc', svm.SVC(C=1.0))])\n",
    "\n",
    "y_list = y.tolist()\n",
    "y_new = []\n",
    "for i in range(len(y_list)):\n",
    "    y_new.append(y_list[i][0])\n",
    "y_array = np.array(y_new)\n",
    "y_array.shape\n",
    "\n",
    "score_means = list()\n",
    "score_stds = list()\n",
    "percentiles = (1, 3, 6, 10, 15, 20, 30, 40, 60, 80, 100)\n",
    "\n",
    "for percentile in percentiles:\n",
    "    clf.set_params(anova__percentile=percentile)\n",
    "    # Compute cross-validation score using 1 CPU\n",
    "    this_scores = cross_val_score(clf, X, y_array, n_jobs=1)\n",
    "    score_means.append(this_scores.mean())\n",
    "    score_stds.append(this_scores.std())\n",
    "\n",
    "plt.errorbar(percentiles, score_means, np.array(score_stds))\n",
    "\n",
    "plt.title('Performance of the SVM-Anova varying the percentile of features selected')\n",
    "plt.xlabel('Percentile')\n",
    "plt.ylabel('Prediction rate')\n",
    "\n",
    "plt.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "Multivariate Analysis\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train/test sets\n",
    "train_X, test_X = train_test_split(X, test_size=0.2, random_state=42)\n",
    "train_y, test_y = train_test_split(y, test_size=0.2, random_state=42)\n",
    "\n",
    "y_list = test_y.tolist()\n",
    "y_new = []\n",
    "for i in range(len(y_list)):\n",
    "    y_new.append(y_list[i][0])\n",
    "test_y = np.array(y_new)\n",
    "\n",
    "# Fit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_mn = LogisticRegression(multi_class='multinomial', solver ='newton-cg')\n",
    "lr_mn.fit(train_X, train_y)\n",
    "\n",
    "# Predict\n",
    "from sklearn import metrics, cross_validation\n",
    "preds = cross_validation.cross_val_predict(lr_mn, test_X, test_y, cv=10)\n",
    "print ('Prediction accuracy: ', metrics.accuracy_score(test_y, preds))\n",
    "print (metrics.classification_report(test_y, preds)) \n",
    "\n",
    "# Reciever Operating Characteristics (ROC)\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "random_state = np.random.RandomState(42)\n",
    "\n",
    "# Convert to Binarize formatting\n",
    "y = data_manipulation[['aPTT_CAT']].copy()\n",
    "yy = y.applymap(int).as_matrix()\n",
    "y = label_binarize(yy, classes=[0, 1])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True, random_state = random_state))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[0], tpr[0], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('ROC AUC Score: ', roc_auc_score(y_test, y_score))\n",
    "\n",
    "# Receiver Operating Characteristic (ROC) with cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Run classifier with cross-validation\n",
    "cv = StratifiedKFold(n_splits=6)\n",
    "classifier = svm.SVC(kernel='linear', probability=True, random_state=random_state)\n",
    "\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 982) # (change based on size of data being run)\n",
    "\n",
    "y = data_manipulation[['aPTT_CAT']].copy()\n",
    "y = label_binarize(y, classes=['SUB-TH', 'TH', 'SUPRA-TH'])\n",
    "#y = y.applymap(int) #change: make y values a one row matrix of ints\n",
    "y_list = y['aPTT_CAT'].tolist()\n",
    "y_new = []\n",
    "for i in range(len(y_list)):\n",
    "    y_new.append(y_list[i])\n",
    "y = np.array(y_new)\n",
    "\n",
    "X = X_cat_day.copy()\n",
    "X = X.applymap(int).as_matrix() #change: make X values a matrix of ints\n",
    "n_samples, n_features = X.shape \n",
    "\n",
    "colors = cycle(['cyan', 'indigo', 'seagreen', 'yellow', 'blue', 'darkorange'])\n",
    "lw = 2\n",
    "\n",
    "i = 0\n",
    "for (train, test), color in zip(cv.split(X, y), colors):\n",
    "    probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=lw, color=color,\n",
    "             label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    i += 1\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k', \n",
    "         label='Luck')\n",
    "\n",
    "mean_tpr /= cv.get_n_splits(X, y)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "plt.plot(mean_fpr, mean_tpr, color='g', linestyle='--',\n",
    "         label='Mean ROC (area = %0.2f)' % mean_auc, lw=lw)\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
