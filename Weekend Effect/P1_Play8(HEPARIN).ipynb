{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# File specific imports\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "rnd.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdatabuffalo/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/ADMISSIONS.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'DISCHTIME', 'ADMISSION_LOCATION', 'ETHNICITY', 'DIAGNOSIS']\n",
    "admissions = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/PATIENTS.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'GENDER', 'DOB', 'EXPIRE_FLAG']\n",
    "patients = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/INPUTEVENTS_CV.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'CHARTTIME', 'ITEMID', 'AMOUNT', 'AMOUNTUOM'] # 'RATE', 'RATEUOM', 'STOPPED' are full of NaN\n",
    "inputevents_cv = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/INPUTEVENTS_MV.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'STARTTIME', 'ENDTIME', 'ITEMID', 'AMOUNT', 'AMOUNTUOM', 'RATE', 'RATEUOM', 'ORDERCATEGORYNAME', 'ORDERCATEGORYDESCRIPTION']\n",
    "inputevents_mv = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/LABEVENTS.csv'\n",
    "cols_to_keep = ['SUBJECT_ID', 'ITEMID', 'CHARTTIME', 'VALUE', 'VALUENUM', 'VALUEUOM', 'FLAG'] # 'HADM_ID' is full of NaN\n",
    "labevents = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/D_ITEMS.csv'\n",
    "cols_to_keep = ['ITEMID', 'LABEL'] #'CATEGORY', 'UNITNAME', 'PARAM_TYPE' are full of NaN\n",
    "d_items = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)\n",
    "\n",
    "csv_path = '/media/bigdatabuffalo/drive/MIMIC3/CSV/D_LABITEMS.csv'\n",
    "cols_to_keep = ['ITEMID', 'LABEL', 'FLUID', 'CATEGORY']\n",
    "d_labitems = pd.read_csv(csv_path, skipinitialspace = True, usecols = cols_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "admissions = admissions.applymap(str)\n",
    "patients = patients.applymap(str)\n",
    "inputevents_cv = inputevents_cv.applymap(str)\n",
    "inputevents_mv  = inputevents_mv .applymap(str)\n",
    "labevents  = labevents.applymap(str) \n",
    "d_items = d_items.applymap(str)\n",
    "d_labitems = d_labitems.applymap(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATIENT INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine admissions and patients\n",
    "patient_info = pd.merge(admissions, patients, on = ['SUBJECT_ID'])\n",
    "\n",
    "# Change Ethnicity to White/Non-White\n",
    "ethnicity = patient_info['ETHNICITY']\n",
    "\n",
    "def get_ethnicity(value):\n",
    "    if value == 'WHITE':\n",
    "        return 'WHITE'\n",
    "    else:\n",
    "        return 'NOT WHITE'\n",
    "\n",
    "list_ethnicity = [get_ethnicity(value) for value in ethnicity]\n",
    "\n",
    "patient_info = patient_info.drop('ETHNICITY', axis = 1)\n",
    "df_ethnicity = pd.DataFrame({'ETHNICITY' : list_ethnicity})\n",
    "patient_info = pd.concat([patient_info, df_ethnicity], axis=1)\n",
    "\n",
    "# Add ages\n",
    "DoB = patient_info['DOB']\n",
    "admDate = patient_info['ADMITTIME']\n",
    "\n",
    "def get_age (birth, current):\n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    birth = birth.replace('-', ' ')\n",
    "    birth = birth.replace(':', ' ')\n",
    "    current = current.replace('-', ' ')\n",
    "    current = current.replace(':', ' ')\n",
    "\n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    birth = birth.split(' ')\n",
    "    current = current.split(' ')\n",
    "\n",
    "    #convert to integers\n",
    "    birth = [int(i) for i in birth]\n",
    "    current = [int(i) for i in current]\n",
    "    \n",
    "    #get age and return it\n",
    "    birth = datetime.datetime(birth[0], birth[1], birth[2], birth[3], birth[4], birth[5])\n",
    "    current = datetime.datetime(current[0], current[1], current[2], current[3], current[4], current[5])\n",
    "    age = relativedelta(current, birth).years\n",
    "    \n",
    "    #adjust for 89+ category\n",
    "    if age == 300:\n",
    "        age = 89\n",
    "    \n",
    "    return age\n",
    "\n",
    "def get_age_category(age):\n",
    "    if age > 88:\n",
    "        return ('89+')\n",
    "    elif age > 60:\n",
    "        return('Elderly')\n",
    "    elif age > 50:\n",
    "        return('50s')\n",
    "    elif age > 40:\n",
    "        return('40s')\n",
    "    elif age > 30:\n",
    "        return('30s')\n",
    "    elif age > 17:\n",
    "        return('20s')\n",
    "    else:\n",
    "        return('Child')\n",
    "\n",
    "ages = []\n",
    "age_categories = []\n",
    "\n",
    "for i in range(len(DoB)):\n",
    "    ages.append(get_age(DoB[i], admDate[i]))\n",
    "\n",
    "for age in ages:\n",
    "    age_categories.append(get_age_category(age))\n",
    "\n",
    "ages_df = pd.DataFrame({'AGE' : ages})\n",
    "ages_cat_df = pd.DataFrame({'AGE_CAT' : age_categories})\n",
    "patient_info = pd.concat([patient_info, ages_df], axis=1)\n",
    "patient_info = pd.concat([patient_info, ages_cat_df], axis=1)\n",
    "\n",
    "# Add LOS\n",
    "admDate = patient_info['ADMITTIME']\n",
    "dischDate = patient_info['DISCHTIME']\n",
    "\n",
    "def get_los (admit, disch):\n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    admit = admit.replace('-', ' ')\n",
    "    admit = admit.replace(':', ' ')\n",
    "    disch = disch.replace('-', ' ')\n",
    "    disch = disch.replace(':', ' ')\n",
    "\n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    admit = admit.split(' ')\n",
    "    disch = disch.split(' ')\n",
    "\n",
    "    #convert to integers\n",
    "    admit = [int(i) for i in admit]\n",
    "    disch = [int(i) for i in disch]\n",
    "    \n",
    "    #get los and return it\n",
    "    admit = datetime.datetime(admit[0], admit[1], admit[2], admit[3], admit[4], admit[5])\n",
    "    disch = datetime.datetime(disch[0], disch[1], disch[2], disch[3], disch[4], disch[5])\n",
    "    los = (disch-admit).total_seconds()/3600\n",
    "    los = round((los/24), 1)\n",
    "\n",
    "    return los\n",
    "\n",
    "los = []\n",
    "\n",
    "for i in range(len(admDate)):\n",
    "    los.append(get_los(admDate[i], dischDate[i]))\n",
    "    \n",
    "los_df = pd.DataFrame({'LOS' : los})\n",
    "patient_info = pd.concat([patient_info, los_df], axis = 1)\n",
    "\n",
    "# Get Day/Night (day is between 8 am : 8 pm)\n",
    "admTime = patient_info['ADMITTIME']\n",
    "\n",
    "def get_day_night (value):\n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    value = value.replace('-', ' ')\n",
    "    value = value.replace(':', ' ')\n",
    "    \n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    date = value.split(' ')\n",
    "    \n",
    "    #leave hour/min/sec, convert to integers\n",
    "    hour = date[3]\n",
    "    int_hour = int(hour)\n",
    "    \n",
    "    #get day/night and return it\n",
    "    if 7 < int_hour < 21:\n",
    "        return 'DAY'\n",
    "    else:\n",
    "        return 'NIGHT'\n",
    "\n",
    "day_night = [get_day_night(value) for value in admTime]\n",
    "\n",
    "day_night_df = pd.DataFrame({'DAY_NIGHT' : day_night})\n",
    "patient_info = pd.concat([patient_info, day_night_df], axis=1)\n",
    "\n",
    "# Get admission day\n",
    "admTime = patient_info['ADMITTIME']\n",
    "\n",
    "def get_day_of_week (value):\n",
    "    date = []\n",
    "    int_date = []\n",
    "    day_of_week = []\n",
    "    \n",
    "    #replace dashes and colons with spaces to make breaking the string up easier\n",
    "    value = value.replace('-', ' ')\n",
    "    value = value.replace(':', ' ')\n",
    "    \n",
    "    #split into a string outputting [year, month, day, hour, minutes, seconds]\n",
    "    date = value.split(' ')\n",
    "    \n",
    "    #delete hour/min/sec, convert to integers\n",
    "    del date[3:6]\n",
    "    int_date = [int(i) for i in date]\n",
    "    \n",
    "    #get day of week and return it\n",
    "    day_of_week = datetime.date(int_date[0], int_date[1], int_date[2]).weekday()\n",
    "    \n",
    "    return day_of_week\n",
    "\n",
    "\n",
    "admTime_weekday = [get_day_of_week(value) for value in admTime]\n",
    "\n",
    "weekday_data_df = pd.DataFrame({'ADM_DAY' : admTime_weekday})\n",
    "patient_info = pd.concat([patient_info, weekday_data_df], axis=1)\n",
    "\n",
    "# Clean up columns\n",
    "patient_times_info = patient_into[['ADMITTIME', 'DISCHTIME', 'DOB']].copy()\n",
    "patient_info = patient_info.drop(['ADMITTIME', 'DISCHTIME', 'DOB'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LABEVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert labevents[FLAG] : NaN to 0, abnomal to 1\n",
    "labevents['FLAG'] = labevents['FLAG'].replace('nan', 0)\n",
    "labevents['FLAG'] = labevents['FLAG'].replace('abnormal', 1)\n",
    "\n",
    "# Merge d_labitems onto labevents \n",
    "labevents = pd.merge(labevents, d_labitems, on = 'ITEMID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUTEVENTS (CV AND MV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge d_items onto inputevents_cv, and inputevents_mv separately\n",
    "inputevents_cv = pd.merge(inputevents_cv, d_items, on = 'ITEMID')\n",
    "inputevents_mv = pd.merge(inputevents_mv, d_items, on = 'ITEMID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heparin Data Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patient_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. UNIQUE ADULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patient_info = patient_info.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "\n",
    "word_list = ['Heparin']\n",
    "heparin_cv = inputevents_cv[inputevents_cv['LABEL'].str.contains('|'.join(word_list))]\n",
    "heparin_mv = inputevents_mv[inputevents_mv['LABEL'].str.contains('|'.join(word_list))]\n",
    "\n",
    "# Drop Prophylaxis from heparin_mv\n",
    "heparin_mv = heparin_mv[heparin_mv['LABEL'] != 'Heparin Sodium (Prophylaxis)']\n",
    "\n",
    "print(heparin_cv.info())\n",
    "print(heparin_mv.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Groups\n",
    "gp_cv = heparin_cv.groupby('SUBJECT_ID')\n",
    "gp_mv = heparin_mv.groupby('SUBJECT_ID')\n",
    "patient_count = 0\n",
    "\n",
    "for g in gp_cv:\n",
    "    patient_count += 1\n",
    "for g in gp_mv:\n",
    "    patient_count += 1\n",
    "print('Total PT recieving UFH: ', patient_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update patient_info to heparin_patients\n",
    "patient_list_cv = list(gp_cv.groups.keys())\n",
    "patient_list_mv = list(gp_mv.groups.keys())\n",
    "patient_list = patient_list_cv + patient_list_mv\n",
    "\n",
    "heparin_patients = pd.DataFrame({'SUBJECT_ID' : patient_list})\n",
    "heparin_patients = pd.merge(heparin_patients, patient_info, on = 'SUBJECT_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. aPTT MEASUREMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find all aPTT measurements\n",
    "word_list = ['PTT']\n",
    "aPTT = labevents[labevents['LABEL'].str.contains('|'.join(word_list))]\n",
    "\n",
    "# Create Groups\n",
    "gp_ptt = aPTT.groupby('SUBJECT_ID')\n",
    "patient_count = 0\n",
    "\n",
    "for g in gp_ptt:\n",
    "    patient_count += 1\n",
    "\n",
    "print('Total PT with aPTT tests: ', patient_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update heparin_patients\n",
    "patient_list_ptt = list(gp_ptt.groups.keys())\n",
    "aPTT_patients = pd.DataFrame({'SUBJECT_ID' : patient_list_ptt})\n",
    "heparin_patients = pd.merge(heparin_patients, aPTT_patients, on = 'SUBJECT_ID')\n",
    "heparin_patients.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptts = aPTT['VALUE']\n",
    "\n",
    "def get_aPTT_category(ptt):\n",
    "    if ptt == '>150':\n",
    "        return ('SUPRA-TH')\n",
    "    if ptt == '>150.0':\n",
    "        return ('SUPRA-TH')\n",
    "    if ptt == '> 150':\n",
    "        return ('SUPRA-TH')\n",
    "    elif len(ptt) > 5:\n",
    "        return (None)\n",
    "    elif ptt == 'ERROR':\n",
    "        return (None)\n",
    "    ptt = ptt.replace('..', '.')\n",
    "    ptt = float(ptt)\n",
    "    if ptt > 100:\n",
    "        return ('SUPRA-TH')\n",
    "    elif ptt < 60:\n",
    "        return('SUB-TH')\n",
    "    else:\n",
    "        return('TH')\n",
    "\n",
    "ptt_categories = []\n",
    "\n",
    "for ptt in ptts:\n",
    "    ptt_categories.append(get_aPTT_category(ptt))\n",
    "\n",
    "ptt_cat_df = pd.DataFrame({'aPTT_CAT' : ptt_categories})\n",
    "aPTT = aPTT.reset_index(drop = True)\n",
    "aPTT = pd.concat([aPTT, ptt_cat_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. NON TRANSFERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heparin_patients = heparin_patients[heparin_patients.ADMISSION_LOCATION != 'TRANSFER FROM SKILLED NUR']\n",
    "heparin_patients = heparin_patients[heparin_patients.ADMISSION_LOCATION != 'TRANSFER FROM HOSP/EXTRAM']\n",
    "heparin_patients = heparin_patients[heparin_patients.ADMISSION_LOCATION != 'TRANSFER FROM OTHER HEALT']\n",
    "heparin_patients = heparin_patients[heparin_patients.ADMISSION_LOCATION != '** INFO NOT AVAILABLE **']\n",
    "\n",
    "heparin_patients.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#missing - SOFA score is in chartevents (itemid is 20002)\n",
    "# Dosage Time (adm to dose)\n",
    "# Measurement Time (dose to aPTT)\n",
    "# Weight normalized dose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate first aPTT times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_aPTT = aPTT.drop_duplicates(subset = 'SUBJECT_ID', keep = 'first')\n",
    "first_aPTT = first_aPTT.rename(columns = {'CHARTTIME': 'aPTT_TIME'})\n",
    "\n",
    "# Update heparin dosage dataframes\n",
    "word_list = heparin_patients['SUBJECT_ID'].tolist()\n",
    "heparin_cv = heparin_cv.loc[heparin_cv['SUBJECT_ID'].isin(word_list)]\n",
    "heparin_mv = heparin_mv.loc[heparin_mv['SUBJECT_ID'].isin(word_list)]\n",
    "\n",
    "print(heparin_cv.info())\n",
    "print(heparin_mv.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
